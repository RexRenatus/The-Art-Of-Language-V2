{
  "topic_title": "System Resource Monitoring (CPU, Memory, Disk)",
  "category": "Threat Intelligence And Hunting - Threat Intelligence Platforms",
  "flashcards": [
    {
      "question_text": "What is the primary purpose of monitoring CPU utilization in the context of threat intelligence and hunting?",
      "correct_answer": "To detect anomalous spikes that may indicate malicious processes or resource exhaustion attacks.",
      "distractors": [
        {
          "text": "To ensure the system meets minimum performance requirements for general use.",
          "misconception": "Targets [scope confusion]: Focuses on general performance, not security anomalies."
        },
        {
          "text": "To predict future hardware upgrade needs based on historical trends.",
          "misconception": "Targets [misapplication of data]: Uses performance data for capacity planning, not immediate threat detection."
        },
        {
          "text": "To verify that all installed applications are running within expected parameters.",
          "misconception": "Targets [oversimplification]: Ignores that malicious processes can mimic normal application behavior."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Monitoring CPU utilization is crucial because sustained high CPU usage can indicate a denial-of-service attack, cryptomining malware, or other resource-intensive malicious processes, thus enabling threat hunters to identify and investigate anomalies.",
        "distractor_analysis": "The distractors focus on general performance tuning, capacity planning, and application verification, missing the security-centric aspect of anomaly detection for threat hunting.",
        "analogy": "Watching CPU usage is like monitoring a building's electricity meter; a sudden, unexplained surge might mean a new, unauthorized, power-hungry machine has been plugged in, or a system is being overloaded."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "CPU_FUNDAMENTALS",
        "THREAT_HUNTING_BASICS"
      ]
    },
    {
      "question_text": "Which of the following best describes the role of memory (RAM) monitoring in threat hunting?",
      "correct_answer": "Identifying unusual memory allocation patterns or processes consuming excessive memory, which could signify malware or memory-resident attacks.",
      "distractors": [
        {
          "text": "Ensuring that the operating system has enough RAM to run smoothly.",
          "misconception": "Targets [scope limitation]: Focuses on basic OS function, not security threats."
        },
        {
          "text": "Tracking memory usage to optimize application startup times.",
          "misconception": "Targets [misapplication of data]: Uses memory data for performance tuning, not threat detection."
        },
        {
          "text": "Confirming that all installed software is properly loaded into memory.",
          "misconception": "Targets [incorrect focus]: Assumes all loaded software is benign, ignoring malicious processes."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Memory monitoring is vital for threat hunting because malware often resides in RAM, and unusual memory allocation or consumption by specific processes can be strong indicators of malicious activity, enabling the detection of memory-resident threats.",
        "distractor_analysis": "The distractors address general system performance and software loading, failing to recognize that abnormal memory usage is a key indicator for detecting sophisticated malware and memory-based attacks.",
        "analogy": "Monitoring RAM is like checking the inventory of a warehouse's temporary holding area; an unusual amount of space being taken up by an unknown item could signal something illicit has been stored there."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "MEMORY_BASICS",
        "MALWARE_ANALYSIS"
      ]
    },
    {
      "question_text": "Why is monitoring disk I/O (Input/Output) operations critical for threat intelligence and hunting?",
      "correct_answer": "High disk activity from unexpected processes can indicate data exfiltration, malware installation, or reconnaissance activities.",
      "distractors": [
        {
          "text": "To ensure that disk space is not running low, preventing system crashes.",
          "misconception": "Targets [scope confusion]: Focuses on capacity management, not security events."
        },
        {
          "text": "To measure the read/write speeds for optimizing application performance.",
          "misconception": "Targets [misapplication of data]: Uses I/O data for performance tuning, not threat detection."
        },
        {
          "text": "To verify that all scheduled disk defragmentation tasks are completing successfully.",
          "misconception": "Targets [irrelevant process]: Focuses on routine maintenance, ignoring security implications."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Disk I/O monitoring is crucial because excessive or unusual disk activity by specific processes can signal data theft (exfiltration), the writing of malicious files, or the execution of reconnaissance tools, providing actionable intelligence for threat hunters.",
        "distractor_analysis": "The distractors focus on disk space management, performance optimization, and routine maintenance, failing to identify the security implications of abnormal disk I/O patterns indicative of malicious actions.",
        "analogy": "Monitoring disk I/O is like watching a busy loading dock; a sudden, continuous stream of outgoing packages from an unusual bay could mean unauthorized goods are being shipped out."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "DISK_I_O_BASICS",
        "DATA_EXFILTRATION_METHODS"
      ]
    },
    {
      "question_text": "According to NIST SP 800-61 Rev. 2, what is a key component of effective incident handling that relies on system monitoring?",
      "correct_answer": "Analyzing detected events and anomalies to determine the nature and scope of a security incident.",
      "distractors": [
        {
          "text": "Implementing new security controls before an incident occurs.",
          "misconception": "Targets [timing confusion]: Focuses on proactive defense, not reactive incident analysis."
        },
        {
          "text": "Developing a comprehensive disaster recovery plan.",
          "misconception": "Targets [related but distinct process]: DR is a response, but analysis is key to understanding the incident first."
        },
        {
          "text": "Training users on basic cybersecurity hygiene practices.",
          "misconception": "Targets [preventative measure]: User training is important but not the direct outcome of incident analysis."
        }
      ],
      "detailed_explanation": {
        "core_logic": "NIST SP 800-61 Rev. 2 emphasizes that analyzing detected events and anomalies is a critical step in incident handling because it allows security teams to understand what happened, how it happened, and the extent of the compromise, directly leveraging system monitoring data.",
        "distractor_analysis": "The distractors focus on pre-incident prevention, disaster recovery planning, and user training, which are important but do not directly represent the analysis phase of incident handling as described by NIST.",
        "analogy": "Analyzing incident data is like a detective examining a crime scene; they look at all the clues (system logs, resource usage) to understand what happened, who was involved, and the impact."
      },
      "code_snippets": [],
      "difficulty": "advanced",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "NIST_SP_800_61",
        "INCIDENT_RESPONSE_PROCESS"
      ]
    },
    {
      "question_text": "What is the significance of establishing a baseline for normal system resource utilization (CPU, memory, disk) in threat hunting?",
      "correct_answer": "It provides a reference point to identify deviations that may indicate malicious activity.",
      "distractors": [
        {
          "text": "It ensures that systems are running at peak performance at all times.",
          "misconception": "Targets [performance vs. security]: Confuses optimal performance with security anomaly detection."
        },
        {
          "text": "It helps in capacity planning for future hardware purchases.",
          "misconception": "Targets [misapplication of data]: Uses baseline for planning, not real-time threat detection."
        },
        {
          "text": "It simplifies the process of troubleshooting common software errors.",
          "misconception": "Targets [limited scope]: Focuses on benign errors, not sophisticated security threats."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Establishing a baseline is fundamental because it defines what 'normal' system resource behavior looks like; therefore, any significant deviation from this baseline, such as unusual spikes in CPU or disk activity, can be flagged as a potential security incident for investigation.",
        "distractor_analysis": "The distractors focus on performance optimization, capacity planning, and basic troubleshooting, failing to grasp that baselining is a critical prerequisite for anomaly detection in security monitoring.",
        "analogy": "A baseline is like knowing your car's normal engine sound; any strange new noises or vibrations (resource spikes) immediately signal something might be wrong and needs checking."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "BASELINE_CONCEPT",
        "ANOMALY_DETECTION"
      ]
    },
    {
      "question_text": "How can monitoring network connections alongside system resource usage aid threat intelligence and hunting?",
      "correct_answer": "It helps correlate high resource usage with specific network traffic, identifying malicious communication patterns or data exfiltration.",
      "distractors": [
        {
          "text": "It ensures that all network ports are open for maximum connectivity.",
          "misconception": "Targets [security vulnerability]: Promotes open ports, which is a security risk."
        },
        {
          "text": "It verifies that network bandwidth is being utilized efficiently for legitimate applications.",
          "misconception": "Targets [performance focus]: Prioritizes efficiency over detecting malicious traffic."
        },
        {
          "text": "It confirms that the network firewall is configured correctly to block all external access.",
          "misconception": "Targets [incorrect defense]: A firewall blocking all external access would prevent legitimate operations."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Correlating system resource monitoring with network connection data is essential because it allows threat hunters to link unusual resource spikes (e.g., high CPU from a specific process) to specific network activities (e.g., outbound connections to suspicious IPs), thereby identifying data exfiltration or command-and-control (C2) communications.",
        "distractor_analysis": "The distractors suggest open ports, efficient bandwidth use, or complete blocking of external access, none of which accurately describe the security benefit of correlating resource usage with network activity for threat detection.",
        "analogy": "It's like seeing a person in a room suddenly start sweating profusely (high CPU) and then immediately notice them trying to discreetly pass a package out a window (network connection/exfiltration)."
      },
      "code_snippets": [],
      "difficulty": "advanced",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "NETWORK_MONITORING",
        "RESOURCE_MONITORING",
        "C2_COMMUNICATIONS"
      ]
    },
    {
      "question_text": "What is a common 'living off the land' (LOTL) technique that might be detected through system resource monitoring?",
      "correct_answer": "Using legitimate system tools (like PowerShell or WMI) for malicious purposes, which can cause temporary, localized spikes in CPU or disk activity.",
      "distractors": [
        {
          "text": "Exploiting unpatched vulnerabilities in third-party software.",
          "misconception": "Targets [different attack vector]: LOTL focuses on native tools, not external software exploits."
        },
        {
          "text": "Deploying custom malware with unique signatures.",
          "misconception": "Targets [signature-based detection]: LOTL aims to evade signature detection by using legitimate tools."
        },
        {
          "text": "Conducting phishing attacks via email.",
          "misconception": "Targets [different attack vector]: Phishing is an initial access method, not a LOTL technique on the endpoint."
        }
      ],
      "detailed_explanation": {
        "core_logic": "LOTL techniques leverage built-in system tools, such as PowerShell or Windows Management Instrumentation (WMI), for malicious actions. While these tools are legitimate, their unusual or excessive use, detectable via CPU or disk I/O monitoring, can signal an attack, as threat actors use them to avoid introducing new malicious binaries.",
        "distractor_analysis": "The distractors describe other attack methods (vulnerability exploitation, custom malware, phishing) that are distinct from the core concept of LOTL, which relies on abusing legitimate system functionalities.",
        "analogy": "LOTL is like a burglar using a homeowner's own tools (a screwdriver to jimmy a lock) to break in, rather than bringing their own specialized burglary kit."
      },
      "code_snippets": [],
      "difficulty": "expert",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "LOTL_TECHNIQUES",
        "SYSTEM_TOOLS_USAGE"
      ]
    },
    {
      "question_text": "Which of the following is a best practice for collecting system resource logs for threat hunting, as recommended by the Australian Cyber Security Centre (ACSC)?",
      "correct_answer": "Ensure logs capture command execution details and script block logging for PowerShell, and detailed tracking of administrative tasks.",
      "distractors": [
        {
          "text": "Log only successful application launches to reduce noise.",
          "misconception": "Targets [insufficient detail]: Ignores the need to log potentially malicious command executions."
        },
        {
          "text": "Focus solely on disk space usage to prevent storage exhaustion.",
          "misconception": "Targets [limited scope]: Prioritizes capacity over security-relevant event logging."
        },
        {
          "text": "Collect logs from all systems but do not centralize them for analysis.",
          "misconception": "Targets [lack of correlation]: Decentralized logs hinder effective threat hunting and correlation."
        }
      ],
      "detailed_explanation": {
        "core_logic": "The ACSC recommends detailed logging, including command execution and script block logging for PowerShell, because these capture the specific commands and scripts run on a system, which is crucial for identifying malicious LOTL techniques and administrative actions that could indicate a compromise.",
        "distractor_analysis": "The distractors suggest logging only successful launches, focusing only on disk space, or not centralizing logs, all of which are contrary to best practices for effective threat hunting and incident analysis.",
        "analogy": "It's like a security camera only recording when a door opens, but not what the person inside is doing; detailed logging captures the actions, not just the event trigger."
      },
      "code_snippets": [],
      "difficulty": "advanced",
      "question_type": "procedure",
      "bloom_level": "apply",
      "prerequisites": [
        "ACSC_GUIDANCE",
        "POWERSHELL_LOGGING"
      ]
    },
    {
      "question_text": "In the context of threat intelligence, what does 'memory forensics' primarily involve regarding system resource monitoring?",
      "correct_answer": "Analyzing the contents of RAM to find evidence of malware, running processes, network connections, and other volatile data that may not be present on disk.",
      "distractors": [
        {
          "text": "Defragmenting RAM to improve system performance.",
          "misconception": "Targets [incorrect concept]: RAM does not require defragmentation like disks."
        },
        {
          "text": "Monitoring RAM usage to ensure applications have sufficient memory.",
          "misconception": "Targets [basic monitoring vs. forensics]: Focuses on operational status, not deep analysis of volatile data."
        },
        {
          "text": "Allocating more RAM to critical system services.",
          "misconception": "Targets [system tuning vs. forensics]: Focuses on resource management, not evidence gathering."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Memory forensics is crucial in threat hunting because malware often operates in RAM and leaves traces there that are lost upon system reboot. Analyzing this volatile data allows investigators to uncover active threats, running processes, and network communications that might be hidden from disk-based analysis.",
        "distractor_analysis": "The distractors describe RAM defragmentation (a non-existent process), basic operational monitoring, and resource allocation, all of which miss the investigative and forensic purpose of memory analysis in cybersecurity.",
        "analogy": "Memory forensics is like quickly examining the contents of someone's pockets and hands right after they've been caught doing something suspicious, before they can discard the evidence."
      },
      "code_snippets": [],
      "difficulty": "advanced",
      "question_type": "definition",
      "bloom_level": "understand",
      "prerequisites": [
        "MEMORY_FORENSICS",
        "VOLATILE_DATA"
      ]
    },
    {
      "question_text": "Which of the following is a key consideration for log retention for system resource monitoring data used in threat hunting, as per CISA guidance?",
      "correct_answer": "Retain logs for an appropriate period to enable thorough historical analysis, aggregating them in a centralized location to protect from tampering.",
      "distractors": [
        {
          "text": "Delete logs immediately after they are analyzed to save storage space.",
          "misconception": "Targets [short-sightedness]: Prevents historical analysis and re-investigation."
        },
        {
          "text": "Store logs only on the individual systems where they were generated.",
          "misconception": "Targets [lack of centralization]: Hinders correlation and makes logs vulnerable to tampering."
        },
        {
          "text": "Keep logs for a fixed, short duration (e.g., 24 hours) regardless of event type.",
          "misconception": "Targets [inadequate retention]: Insufficient for investigating complex or long-term threats."
        }
      ],
      "detailed_explanation": {
        "core_logic": "CISA emphasizes retaining logs for sufficient periods and centralizing them because historical data is vital for understanding the full scope of an incident, identifying patterns over time, and ensuring logs are protected from tampering, which is essential for reliable threat hunting and incident response.",
        "distractor_analysis": "The distractors suggest immediate deletion, decentralized storage, or fixed short retention, all of which undermine the ability to conduct thorough historical analysis and protect log integrity.",
        "analogy": "Log retention is like keeping old receipts; you need them not just for immediate review, but also to track spending patterns over time or to prove a transaction if a dispute arises later."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "procedure",
      "bloom_level": "apply",
      "prerequisites": [
        "CISA_GUIDANCE",
        "LOG_RETENTION_POLICIES"
      ]
    },
    {
      "question_text": "What is the primary risk associated with shared local administrator credentials across multiple workstations, as highlighted in CISA advisories?",
      "correct_answer": "Facilitates widespread unauthorized access and lateral movement if one workstation is compromised.",
      "distractors": [
        {
          "text": "Increases the likelihood of accidental deletion of system files.",
          "misconception": "Targets [unrelated risk]: Focuses on accidental user error, not malicious actor exploitation."
        },
        {
          "text": "Slows down the login process for legitimate administrators.",
          "misconception": "Targets [performance impact]: Shared credentials don't inherently slow down logins; they increase security risk."
        },
        {
          "text": "Makes it harder to track which administrator performed specific actions.",
          "misconception": "Targets [auditability issue]: While true, the primary risk is broader compromise, not just auditability."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Shared local administrator credentials pose a significant risk because compromising a single workstation with these credentials grants an attacker access to administrative privileges on many other machines, enabling rapid lateral movement and widespread compromise, as detailed in CISA advisories.",
        "distractor_analysis": "The distractors focus on accidental deletion, login performance, or auditability issues, which are secondary concerns compared to the critical risk of widespread unauthorized access and lateral movement enabled by shared admin credentials.",
        "analogy": "Using shared admin passwords is like giving everyone in a building the master key to every apartment; if one person misuses it, all apartments are at risk."
      },
      "code_snippets": [],
      "difficulty": "advanced",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "CREDENTIAL_MANAGEMENT",
        "LATERAL_MOVEMENT"
      ]
    },
    {
      "question_text": "How can monitoring system resource usage help detect 'living off the land' (LOTL) techniques like PowerShell abuse?",
      "correct_answer": "By identifying unusual or excessive CPU/disk activity associated with PowerShell processes, even if PowerShell itself is a legitimate tool.",
      "distractors": [
        {
          "text": "By detecting the presence of PowerShell executables on the system.",
          "misconception": "Targets [false positive risk]: PowerShell is a legitimate tool; its mere presence isn't malicious."
        },
        {
          "text": "By ensuring PowerShell is updated to the latest version.",
          "misconception": "Targets [patching vs. behavior]: Focuses on software versioning, not the behavior of the tool."
        },
        {
          "text": "By blocking all PowerShell scripts from running automatically.",
          "misconception": "Targets [overly restrictive policy]: This would break legitimate administrative functions."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Monitoring resource usage helps detect LOTL techniques like PowerShell abuse because while PowerShell is a legitimate tool, its malicious use often involves running complex, resource-intensive scripts or commands that manifest as abnormal CPU spikes or high disk I/O, providing a behavioral indicator for threat hunters.",
        "distractor_analysis": "The distractors focus on detecting the tool itself, patching it, or blocking it entirely, rather than monitoring its behavior and resource consumption, which is key to identifying malicious LOTL usage.",
        "analogy": "It's like noticing a chef suddenly using a lot of energy and making a mess in the kitchen (high resource usage) with a common kitchen tool (PowerShell); you'd investigate what they're actually cooking (the script's purpose)."
      },
      "code_snippets": [],
      "difficulty": "expert",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "LOTL_TECHNIQUES",
        "POWERSHELL_ABUSE",
        "BEHAVIORAL_ANOMALY_DETECTION"
      ]
    },
    {
      "question_text": "What is the role of 'system monitoring' as defined in NIST SP 800-53 Rev. 5, SI-4?",
      "correct_answer": "To observe events occurring within the system and at its external interfaces to detect attacks, unauthorized connections, and unauthorized use.",
      "distractors": [
        {
          "text": "To solely focus on external network traffic for intrusion detection.",
          "misconception": "Targets [limited scope]: SI-4 explicitly includes internal monitoring."
        },
        {
          "text": "To automatically patch all vulnerabilities as they are discovered.",
          "misconception": "Targets [different control family]: Patching is typically handled by CM (Configuration Management) controls."
        },
        {
          "text": "To provide detailed performance metrics for hardware upgrades.",
          "misconception": "Targets [misapplication of data]: While monitoring provides metrics, the primary security goal is detection, not capacity planning."
        }
      ],
      "detailed_explanation": {
        "core_logic": "NIST SP 800-53 SI-4 defines system monitoring as observing both internal system events and external interface activities because this comprehensive approach is necessary to detect a wide range of threats, including attacks, unauthorized network access, and misuse of system resources, thereby supporting incident response.",
        "distractor_analysis": "The distractors incorrectly limit monitoring to external traffic, confuse it with automated patching, or misrepresent its primary security objective as performance tuning rather than threat detection.",
        "analogy": "System monitoring is like having security cameras inside and outside a building, watching who enters, exits, and what they do inside, to ensure safety and detect suspicious activity."
      },
      "code_snippets": [],
      "difficulty": "advanced",
      "question_type": "definition",
      "bloom_level": "understand",
      "prerequisites": [
        "NIST_SP_800_53",
        "SYSTEM_MONITORING_CONCEPTS"
      ]
    },
    {
      "question_text": "When analyzing system resource logs for threat hunting, what does 'timestamp consistency' refer to, as emphasized in ACSC guidance?",
      "correct_answer": "Ensuring all logs use a synchronized, accurate time source and a consistent date-time format (e.g., ISO 8601 with UTC) across all systems.",
      "distractors": [
        {
          "text": "Using the same time zone for all servers, regardless of their physical location.",
          "misconception": "Targets [oversimplification]: UTC is preferred to avoid time zone issues entirely."
        },
        {
          "text": "Recording only the hour and minute of events to save log space.",
          "misconception": "Targets [insufficient granularity]: Lacks the precision needed for accurate event correlation."
        },
        {
          "text": "Allowing each system to use its own local time settings.",
          "misconception": "Targets [lack of correlation]: Inconsistent times make it impossible to accurately sequence events across systems."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Timestamp consistency is critical because accurate, synchronized timestamps (preferably UTC in ISO 8601 format) across all systems enable threat hunters to correctly correlate events, reconstruct timelines of malicious activity, and understand the sequence of actions during an incident, which is impossible with disparate or inaccurate time data.",
        "distractor_analysis": "The distractors suggest using only one time zone, insufficient time granularity, or allowing local time settings, all of which would prevent accurate event correlation and timeline reconstruction necessary for effective threat hunting.",
        "analogy": "Timestamp consistency is like ensuring all clocks in a synchronized security system are set to the exact same time; without it, you can't tell if event A happened before or after event B across different cameras."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "definition",
      "bloom_level": "understand",
      "prerequisites": [
        "ACSC_GUIDANCE",
        "LOG_CORRELATION",
        "TIME_SYNCHRONIZATION"
      ]
    },
    {
      "question_text": "What is the primary benefit of using a Security Information and Event Management (SIEM) system for system resource monitoring data in threat intelligence?",
      "correct_answer": "To centralize, correlate, and analyze logs from various sources, enabling the detection of complex threats that might be missed by individual system monitoring.",
      "distractors": [
        {
          "text": "To automatically patch systems based on detected resource anomalies.",
          "misconception": "Targets [unknown]: Not specified"
        },
        {
          "text": "To provide real-time performance tuning for individual applications.",
          "misconception": "Targets [limited scope and function]: SIEMs focus on security events, not granular application performance tuning."
        },
        {
          "text": "To store all system logs indefinitely without any data tiering.",
          "misconception": "Targets [storage inefficiency]: SIEMs often involve data tiering (hot/cold storage) and retention policies, not indefinite storage of all raw data."
        }
      ],
      "detailed_explanation": {
        "core_logic": "A SIEM is invaluable for threat intelligence because it aggregates and correlates resource monitoring data from disparate systems, allowing analysts to identify patterns, anomalies, and sophisticated attack chains that would be invisible when looking at individual logs, thereby enhancing detection capabilities.",
        "distractor_analysis": "The distractors misrepresent SIEMs as patching tools, performance tuners, or indefinite storage solutions, failing to capture their core function of centralized security event analysis and correlation.",
        "analogy": "A SIEM is like a central command center that collects reports from all security guards (individual systems) and uses them to piece together a larger picture of potential threats, rather than each guard reporting only on their immediate vicinity."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "definition",
      "bloom_level": "understand",
      "prerequisites": [
        "SIEM_BASICS",
        "THREAT_INTELLIGENCE_PLATFORMS"
      ]
    }
  ],
  "generation_metadata": {
    "model": "google/gemini-2.5-flash-lite",
    "num_generated": 15,
    "temperature": 0.1,
    "web_citations": [],
    "research_method": "openrouter_web_plugin",
    "search_query": "System Resource Monitoring (CPU, Memory, Disk) Threat Intelligence And Hunting best practices",
    "latency_ms": 25609.734
  },
  "timestamp": "2026-01-04T03:05:13.391112"
}