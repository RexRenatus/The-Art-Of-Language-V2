version: '2.0'
metadata:
  topic_title: MISP Taxonomies and Tagging
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: Threat Intelligence And Hunting
    level_3_subdomain: Threat Intelligence Platforms
    level_4_entry_domain: 006_Open Source and Commercial Platforms
    level_5_entry_subdomain: Open Source TIP Solutions
    level_6_topic: MISP Taxonomies and Tagging
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 017_threat-intelligence-and-hunting
    subdomain: 005_threat-intelligence-platforms
  exa_sources: []
  voting:
    consensus_reached: true
    approval_percentage: 1.0
    total_voters: 7
  generation_timestamp: '2026-01-04T03:04:45.383723'
learning_objectives:
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
active_learning:
  discussion_prompt: Debate the trade-offs between using standardized MISP taxonomies versus custom tags in a multi-organization
    threat sharing scenario. Use real-world examples like financial fraud data sharing or SolarWinds breach IOCs to argue
    for reliability, interoperability, and flexibility.
  peer_teaching: Explain the key concepts to a partner without using technical jargon.
  problem_solving: Given a scenario, apply the framework to solve the problem.
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol: 'Generate plausible distractors based on: 1) Common misconceptions (e.g., confuse predicate with value);
    2) Edge cases (e.g., invalid syntax like missing quotes); 3) Real-world variants (e.g., non-MISP tags like simple keywords);
    4) Partial truths (e.g., correct namespace but wrong predicate). Ensure distractors test nuance without being obvious.'
system_prompt: 'You are an expert flashcard generator for cybersecurity education, specializing in Threat Intelligence Platforms.
  Topic: ''MISP Taxonomies and Tagging'' (Hierarchy: Cybersecurity > Threat Intelligence And Hunting > Threat Intelligence
  Platforms > 006_Open Source and Commercial Platforms > Open Source TIP Solutions > MISP Taxonomies and Tagging). Use this
  comprehensive pedagogical framework to generate 20-30 high-quality flashcards.


  **Learning Objectives (span Bloom''s Taxonomy):** [Insert full learning_objectives array here].


  **Active Learning Integration:** Tie flashcards to activitiesâ€”e.g., questions prompting debate (discussion), parsing demos
  (peer teaching), or IOC tagging (problem-solving). [Insert full active_learning object here].


  **Scaffolding Layers (progress from foundation to integration):** [Insert full scaffolding object here]. Distribute flashcards:
  30% Layer 1-2 (remember/understand), 40% Layer 3 (apply/analyze), 30% Layer 4 (evaluate/create).


  **Content Sources:** Core concepts from MISP-project.org and misp-standard.org: MISP for IOC sharing; machine tags as namespace:predicate=value
  (e.g., admiralty-scale:source-reliability=''a''); taxonomies like cert-xlm, veris; STIX integration via exports/labels;
  best practices for tagging events/attributes.


  **Output 20-30 Flashcards Exactly in JSON Array:** Follow flashcard_schema precisely. Vary question types: definitional
  (Layer 1), parsing (Layer 2), scenario application (Layer 3), evaluation (Layer 4). Ensure university-level rigor, active
  recall, spaced repetition optimization (concise fronts, detailed backs). No duplicates; cover voter priorities (e.g., STIX
  completion, custom tags).'
