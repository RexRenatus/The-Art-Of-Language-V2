version: '2.0'
metadata:
  topic_title: 'DREAD: Discoverability Assessment'
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: Threat Intelligence And Hunting
    level_3_subdomain: Threat Intelligence Frameworks
    level_4_entry_domain: 003_Threat 001_Intelligence Frameworks and Models
    level_5_entry_subdomain: 005_Threat Modeling Methodologies
    level_6_topic: 'DREAD: Discoverability Assessment'
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 017_threat-intelligence-and-hunting
    subdomain: 003_threat-intelligence-frameworks
  exa_sources: []
  voting:
    consensus_reached: true
    approval_percentage: 1.0
    total_voters: 7
  generation_timestamp: '2026-01-04T02:30:14.777845'
learning_objectives:
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
active_learning:
  discussion_prompt: 'In a group discussion, debate the discoverability of two vulnerabilities: a publicly disclosed CVE on
    a common port (high discoverability) versus an internal configuration flaw in a private network (low discoverability).
    How does discoverability change if threat intelligence reveals attacker scanning tools? Support with factors from DREAD.'
  peer_teaching: Explain the key concepts to a partner without using technical jargon.
  problem_solving: Given a scenario, apply the framework to solve the problem.
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol:
  - Identify common misconceptions about the topic
  - Create plausible but incorrect alternatives
  - Ensure distractors are similar in length and complexity
  - Avoid obviously wrong answers
  - Include partial truths that require deeper understanding
system_prompt: 'You are an expert flashcard generator for cybersecurity education. Topic: DREAD: Discoverability Assessment
  (Category: Cybersecurity > Threat Intelligence And Hunting > Threat Intelligence Frameworks > 003_Threat 001_Intelligence
  Frameworks and Models > 005_Threat Modeling Methodologies > DREAD: Discoverability Assessment).


  Incorporate these pedagogical elements:

  - Learning Objectives: [insert full list above]

  - Active Learning: [insert summaries, e.g., ''Embed discussion-style questions'']

  - Scaffolding: Use 4 layers progressively; tag each flashcard with layer (e.g., #Layer1).

  - Prior Knowledge: Link to STRIDE/CVSS/DREAD overview.

  - Examples: High (public CVE like Heartbleed), Low (internal zero-day).

  - Sources: Microsoft DREAD, NIST SP 800-30, ISO 27001 (vulnerability mgmt).

  - Factors: Visibility, info availability, scanning ease.


  Generate flashcards following this exact schema: Output as JSON array of objects, each with ''type'', ''layer'', ''bloom_level'',
  ''front'', ''back'' (with ''answer'', ''explanation'', ''distractors'' if MCQ). Balance across objectives/layers. Distractors:
  3 plausible (misconceptions, partial facts). Ensure spaced repetition: atomic, active recall. No spoilers on front. High-quality,
  error-free.'
