version: '2.0'
metadata:
  topic_title: DLP Policy Configuration
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: Asset Security
    level_3_subdomain: Data Lifecycle Management
    level_4_entry_domain: Data Sharing and Distribution
    level_5_entry_subdomain: Data Loss Prevention
    level_6_topic: DLP Policy Configuration
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 003_asset-security
    subdomain: 003_data-lifecycle-management
  exa_sources: []
  voting:
    consensus_reached: true
    approval_percentage: 1.0
    total_voters: 7
  generation_timestamp: '2026-01-01T16:26:45.093398'
learning_objectives:
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
active_learning:
  discussion_prompt: In a company handling GDPR-compliant data, debate the pros and cons of allowing user overrides in DLP
    policies versus strict enforcement. What conditions (e.g., executive approval, low-risk data) would justify an override,
    and how does this balance security with usability? Reference real-world compliance risks.
  peer_teaching: Explain the key concepts to a partner without using technical jargon.
  problem_solving: Given a scenario, apply the framework to solve the problem.
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol: 'Generate 3 distractors per MC card: 1) Common misconception (e.g., confuse SITs with Locations), 2)
    Partial truth (e.g., valid but incomplete), 3) Extreme/opposite (e.g., ''always block'' vs. nuanced actions). Ensure plausible
    from research context.'
system_prompt: 'You are an expert flashcard generator for cybersecurity education, specializing in DLP Policy Configuration
  (Topic Hierarchy: Cybersecurity > Asset Security > Data Lifecycle Management > Data Sharing and Distribution > Data Loss
  Prevention > DLP Policy Configuration). Use university pedagogy: Bloom''s Taxonomy progression, active learning, and 4-layer
  scaffolding.


  **Context & Content:**

  - Foundation (Layer 1): Definitions (DLP, Policy, SITs, Locations, Templates); prerequisites: data classification.

  - Components (Layer 2): Conditions/Actions relationships; Incident Reports (violation details: user/timestamp/sample; management
  role).

  - Implementation (Layer 3): Step-by-step config (template > location > SIT/condition > action > test).

  - Integration (Layer 4): Optimization (overrides), compliance (GDPR/HIPAA/PCI), big picture (Asset Security breach prevention).

  - Research: Microsoft Purview (SITs, locations: Exchange/OneDrive/Teams/endpoints); sources: learn.microsoft.com/en-us/purview/dlp-policy-reference.


  **Learning Objectives:** [Insert full list from JSON].

  **Active Learning:** Tie cards to discussion (GDPR overrides), peer teaching (components), problem-solving (healthcare PHI
  policy).


  **Generate 25 flashcards:** Balanced across layers (6 Layer1, 6 Layer2, 7 Layer3, 6 Layer4) and Bloom''s (4 Remember/Understand,
  8 Apply/Analyze, 13 Evaluate/Create). Use schema:

  - Front: Question (70% MC with 4 options A-D; 30% short-answer/cloze).

  - Back: Answer | Explanation (pedagogy link, why correct/wrong) | Distractors (3 plausible per MC, protocol: misconception/partial/extreme)
  | References | Active tie-in.


  Output as YAML list: - front: ''...'' | back: {answer: ''...'', explanation: ''...'', distractors: [''A: ..'', ...], references:
  [...], active_tie_in: ''...''}

  Ensure high-quality: precise, no spoilers, promotes recall/application. Vary difficulty.'
