version: '2.0'
metadata:
  topic_title: Production Data Sanitization
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: Asset Security
    level_3_subdomain: Data Security Controls
    level_4_entry_domain: Data Masking and Anonymization
    level_5_entry_subdomain: Test Data Management
    level_6_topic: Production Data Sanitization
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 003_asset-security
    subdomain: 004_data-security-controls
  exa_sources: []
  voting:
    consensus_reached: false
    approval_percentage: 0.56
    total_voters: 7
  generation_timestamp: '2026-01-01T16:36:53.610060'
learning_objectives:
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
active_learning:
  discussion_prompt: In a group discussion, debate the trade-offs between using fully synthetic test data versus masked production
    data. Consider costs, realism for testing, and re-identification risks. Support arguments with real-world breach examples
    (e.g., test environments exposing PII).
  peer_teaching: Explain the key concepts to a partner without using technical jargon.
  problem_solving: Given a scenario, apply the framework to solve the problem.
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol: 'Generate 3 plausible distractors: 1) Common misconception (e.g., confuse masking with encryption);
    2) Partial truth/overgeneralization (e.g., ''always use destruction'' ignoring reuse); 3) Extreme/alternative method (e.g.,
    full anonymization when masking suffices). Ensure distractors align with voter-noted confusions like media sanitization
    vs. test data masking.'
system_prompt: 'You are an expert flashcard generator for cybersecurity education, specializing in CISSP Domain 2: Asset Security.
  Topic: Production Data Sanitization (Hierarchy: Cybersecurity > Asset Security > Data Security Controls > Data Masking and
  Anonymization > Test Data Management > Production Data Sanitization). Focus ACCURATELY on sanitizing production data for
  dev/test environments via masking/anonymization (NOT media disposal per NIST SP 800-88).


  Incorporate:

  - Learning objectives: [PASTE FULL LIST FROM JSON]

  - Scaffolding: [PASTE FULL 4 LAYERS FROM JSON]

  - Active learning: Draw questions from [PASTE ACTIVITIES FROM JSON]

  - Related concepts: Link to CIA Triad, data classification, lifecycle; distinguish masking (reversible format-preserving)
  vs. anonymization (irreversible); best practices (classify, mask, verify); compliance (GDPR pseudonymization); tools (Delphix,
  Informatica); big picture (breach prevention in test envs).


  Generate 25 flashcards in EXACT JSON array format: [{''front'': ''...'', ''back'': {''correct_answer'': ''...'', ''explanation'':
  ''...'', ''distractors'': [''A'', ''B'', ''C''], ''bloom_level'': ''...'', ''scaffolding_layer'': ''...''}}, ...]. Follow
  flashcard schema strictly: MCQs with 4 options (1 correct), plausible distractors per protocol. Balance Bloom''s progression
  (lower to higher cognition), cover all scaffolding layers, ensure university pedagogy (active recall, spaced repetition).
  Voter consensus: Prioritize accuracy, completeness (methods: masking/tokenization/etc., verification), cognitive progression.'
