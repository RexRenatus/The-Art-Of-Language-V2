version: '2.0'
metadata:
  topic_title: Differential Privacy
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: Asset Security
    level_3_subdomain: Data Security Controls
    level_4_entry_domain: Data Masking and Anonymization
    level_5_entry_subdomain: Data Anonymization and Pseudonymization
    level_6_topic: Differential Privacy
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 003_asset-security
    subdomain: 004_data-security-controls
  exa_sources: []
  voting:
    consensus_reached: true
    approval_percentage: 0.83
    total_voters: 7
  generation_timestamp: '2026-01-01T16:33:14.436900'
learning_objectives:
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
active_learning:
  discussion_prompt: Debate the trade-offs between privacy (small ε) and utility in differential privacy. Using real-world
    examples like Apple's emoji suggestion or US Census data, argue for optimal ε values in different scenarios and discuss
    implications for cybersecurity compliance (e.g., GDPR, HIPAA).
  peer_teaching: Explain the key concepts to a partner without using technical jargon.
  problem_solving: Given a scenario, apply the framework to solve the problem.
  additional_activities: []
scaffolding:
- level: 1
  name: Layer 1
  focus: ''
  content: 'Basic terms and concepts: Define differential privacy (rigorous framework bounding privacy loss via indistinguishability
    of outputs from neighboring datasets); key parameters ε (privacy budget, smaller=stronger privacy), δ (failure probability);
    neighboring datasets; units of privacy (event-level: differ by one record; user-level: differ by one user).'
- level: 2
  name: Layer 2
  focus: ''
  content: 'Framework structure per NIST SP 800-226: Relationships between ε, δ, sensitivity; ''differential privacy pyramid''
    (base: definitions; middle: mechanisms like Laplace/Gaussian; top: composition/optimization); factors for consideration
    (privacy budget management, units selection).'
- level: 3
  name: Layer 3
  focus: ''
  content: 'Practical mechanisms: Step-by-step Laplace (noise ~ Lap(Δf/ε), Δf=sensitivity); Gaussian (for (ε,δ)-DP); query
    release processes; simulation examples; common pitfalls (e.g., confusing ε with accuracy loss).'
- level: 4
  name: Layer 4
  focus: ''
  content: 'Advanced connections: Link to other PETs (pseudonymization, masking); composition theorems for sequential queries;
    role in cybersecurity hierarchy (Asset Security > Data Security Controls > protecting sensitive data releases); compliance
    (GDPR, HIPAA); optimization in real-world apps (e.g., Census, health analytics).'
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol: 'Generate 3 distractors for MCQs: 1) superficially similar but wrong (e.g., ε as accuracy measure);
    2) common misconception (e.g., neighboring datasets differ by entire users vs. records); 3) edge case reversal (e.g.,
    larger ε = stronger privacy). Ensure plausible for cybersecurity learners.'
system_prompt: 'You are an expert flashcard generator for cybersecurity education, specializing in Differential Privacy (Topic
  Hierarchy: Cybersecurity > Asset Security > Data Security Controls > Data Masking and Anonymization > Data Anonymization
  and Pseudonymization > Differential Privacy). Use the provided learning objectives, active learning components, scaffolding
  layers (with prerequisites), and flashcard schema to generate 50 high-quality flashcards.


  Incorporate:

  - NIST SP 800-226 details: ''Differential privacy pyramid'' (definitions > mechanisms > composition); full guidelines on
  ε, δ, sensitivity, units.

  - Big picture: Role in protecting assets via quantifiable privacy; compliance (GDPR, HIPAA).

  - Voter consensus: Trade-offs, problem-solving (e.g., health records query), misconceptions.

  - Pedagogy: Progress through Bloom''s; link to anonymization/pseudonymization.


  Output ONLY a JSON array of 50 flashcards, each strictly matching the schema (no extra fields). Ensure variety: Cover all
  objectives/layers; distractors per protocol; explanations tie to real-world (Apple, Census, HIPAA).


  Schema reminder: {paste full schema here}.


  Generate now.'
