<?xml version="1.0" encoding="UTF-8"?>
<topic_prompt version="2.0">
  <metadata>
    <topic_title>Differential Privacy</topic_title>
    <hierarchy>
      <category>Cybersecurity</category>
      <domain>Security Architecture And Engineering</domain>
      <subdomain>Cloud Service Models</subdomain>
      <entry_domain>Cross-Model Security Controls</entry_domain>
      <entry_subdomain>Data Protection and Privacy</entry_subdomain>
    </hierarchy>
    <voting_summary>
      <consensus>True</consensus>
      <approval>100.0%</approval>
      <voters>7</voters>
    </voting_summary>
    <generation_timestamp>2026-01-01T13:35:33.803424</generation_timestamp>
  </metadata>
  <learning_objectives level="bloom_taxonomy">
    <objective level="remember" measurable="true" verbs="define">Define key terminology</objective>
    <objective level="understand" measurable="true" verbs="explain">Explain core concepts</objective>
    <objective level="apply" measurable="true" verbs="apply">Apply knowledge to scenarios</objective>
    <objective level="analyze" measurable="true" verbs="analyze">Analyze relationships</objective>
  </learning_objectives>
  <active_learning>
    <discussion_prompt>How would you apply this concept in your work environment?</discussion_prompt>
    <peer_teaching>In pairs, one student teaches the step-by-step Laplace mechanism (sensitivity → noise scale → addition), while the other teaches the Gaussian mechanism; switch roles and quiz each other on formulas and cloud applicability.</peer_teaching>
    <problem_solving>Given a cloud query summing user transaction counts (sensitivity Δf=1, ε=1.0), apply the Laplace mechanism to add noise; then evaluate utility loss and propose optimizations for cross-model security in AWS Glue.</problem_solving>
  </active_learning>
  <scaffolding>
    <layer level="1" name="Foundation">
      <focus>Basic terminology and definitions</focus>
      <content/>
    </layer>
    <layer level="2" name="Components">
      <focus>Framework components and structure</focus>
      <content/>
    </layer>
    <layer level="3" name="Implementation">
      <focus>Practical implementation steps</focus>
      <content/>
    </layer>
    <layer level="4" name="Integration">
      <focus>Advanced integration and optimization</focus>
      <content/>
    </layer>
  </scaffolding>
  <flashcard_generation>
    <output_schema>
      <field name="question" type="string"/>
      <field name="correct_answer" type="string"/>
      <field name="distractors" type="[{'text': 'string', 'explanation': 'string'}]"/>
      <field name="explanation" type="string"/>
      <field name="bloom_level" type="enum"/>
      <field name="topic_hierarchy" type="object"/>
    </output_schema>
    <distractor_protocol>
      <step number="1">Identify common misconceptions about the topic</step>
      <step number="2">Create plausible but incorrect alternatives</step>
      <step number="3">Ensure distractors are similar in length and complexity</step>
      <step number="4">Avoid obviously wrong answers</step>
      <step number="5">Include partial truths that require deeper understanding</step>
    </distractor_protocol>
    <system_prompt>You are an expert flashcard generator for cybersecurity education, specializing in Differential Privacy within the topic hierarchy: Level 1: Cybersecurity &gt; Level 2: Security Architecture And Engineering &gt; Level 3: Cloud Service Models &gt; Level 4: Cross-Model Security Controls &gt; Level 5: Data Protection and Privacy &gt; Level 6: Differential Privacy.
Generate 20-30 high-quality flashcards optimized for spaced repetition and active recall. Base content on:
- Research: DP definition (output nearly identical with/without one individual's data), ε (privacy budget, smaller=stronger), δ (failure prob), neighboring datasets, event/user-level privacy, Laplace (noise Lap(Δf/ε)), Gaussian, NIST SP 800-226 (DP guidelines for federal stats).
- Big picture: Cloud role (IaaS/PaaS/SaaS data protection), compliance (GDPR/HIPAA), re-identification prevention.
- Prior knowledge: Probability (Laplace/Gaussian), basic privacy.
**Learning Objectives (span Bloom's Taxonomy):** [Insert the 6 objectives above].
**Scaffolding Layers:** [Insert the 4 layers above]. Balance coverage across layers.
**Active Learning Integration:** Draw from discussion (event vs user), peer-teach (mechanisms), problem-solving (Laplace computation) for contextual explanations.
**Output Format (JSON array of flashcards):** Strictly follow flashcard_schema:
{
  "flashcards": [
    {
      "front": "Question...",
      "back": {
        "correct_answer": "...",
        "explanation": "Link to objective/layer/context...",
        "distractors": [
          {"distractor": "...", "why_wrong": "..."},
          {"distractor": "...", "why_wrong": "..."},
          {"distractor": "...", "why_wrong": "..."}
        ]
      },
      "bloom_level": "REMEMBER|UNDERSTAND|APPLY|ANALYZE|EVALUATE|CREATE",
      "scaffolding_layer": "1|2|3|4"
    }
  ]
}
Ensure: 40% multiple-choice (3 distractors exactly), 30% cloze, 30% computation/open. Measurable, precise formulas. No hints on front. Educational, unbiased.</system_prompt>
  </flashcard_generation>
</topic_prompt>