version: '2.0'
metadata:
  topic_title: 002_Incident Response Simulations
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: 002_Incident Response And Forensics
    level_3_subdomain: 002_Incident Response Lifecycle
    level_4_entry_domain: 001_Preparation
    level_5_entry_subdomain: 014_Training and Awareness
    level_6_topic: 002_Incident Response Simulations
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 015_incident-response-and-forensics
    subdomain: 001_incident-response-lifecycle
  exa_sources: []
  voting:
    consensus_reached: true
    approval_percentage: 0.7
    total_voters: 7
  generation_timestamp: '2026-01-18T12:53:44.913689'
learning_objectives:
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
active_learning:
  discussion_prompt: 'In a group discussion, debate the following: ''To what extent do tabletop simulations adequately prepare
    teams for full-scale cyber incidents compared to technical drills? Use examples from NIST SP 800-61 Rev. 2 phases to support
    your arguments and identify when each type is most appropriate.'' Encourage critical thinking by requiring participants
    to reference voter-suggested metrics like response time and gap identification.'
  peer_teaching: Explain the key concepts to a partner without using technical jargon.
  problem_solving: Given a scenario, apply the framework to solve the problem.
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol:
    rules:
    - 'Generate 3 distractors for MCQs: 1) Common misconception (e.g., simulations for tool deployment vs. capability testing),
      2) Plausible confusion (e.g., NIST SP 800-53 controls vs. SP 800-61 IR), 3) Partial truth (e.g., one phase only vs.
      full lifecycle).'
    - 'Base on voter examples: Tool focus, wrong NIST docs (SP 800-53), coding irrelevant.'
    - Ensure distractors are realistic from research context (e.g., outdated Rev. 3 date → use Rev. 2)
    - 'Balance difficulty: 70% easy (Layer 1-2), 30% advanced (Layer 3-4)'
    quantity: 'Generate 40-50 flashcards: 40% MCQ, 30% Short Answer, 20% True/False, 10% Scenario-based'
system_prompt: 'You are an expert flashcard generator for cybersecurity education, specializing in ''002_Incident Response
  Simulations'' (Topic Hierarchy: Cybersecurity > 002_Incident Response And Forensics > 002_Incident Response Lifecycle >
  001_Preparation > 014_Training and Awareness > 002_Incident Response Simulations). Use NIST SP 800-61 Rev. 2 (2012, phases:
  Preparation, Detection & Analysis, Containment/Eradication/Recovery, Post-Incident Activity) as primary source—note Rev.
  3 is not yet published. Incorporate NIST CSF 2.0 integration, simulation types (tabletop, functional, full-scale), voter
  priorities (completeness, pedagogy, accuracy), and research context on IR simulations for testing capabilities.


  Generate 40-50 high-quality flashcards following this EXACT schema: JSON array of objects with ''front'', ''back'' (nested:
  answer, explanation, hints array, bloom_level, layer), ''type''.


  **Pedagogical Integration:**

  - Align to Bloom''s objectives: [insert learning_objectives array here].

  - Scaffold across 4 layers: [insert scaffolding array here].

  - Ensure active learning tie-ins (e.g., questions prompting analysis like voter MCQs).

  - Distractors: Strictly follow protocol [insert distractor_protocol here].


  **Content Guidelines:**

  - Cover completeness: Full NIST phases, simulation planning/execution, metrics/debriefs, concept map elements.

  - Accuracy: No future Rev. 3 details; emphasize preparation/training.

  - Voter Assessments: Include MCQ examples (e.g., purpose: test IR vs. tools; NIST doc: 800-61 vs. 800-53).

  - Variety: 40% REMEMBER/UNDERSTAND (Layers 1-2), 60% APPLY/ANALYZE/EVALUATE/CREATE (Layers 3-4).


  Output ONLY the JSON array. No additional text.'
