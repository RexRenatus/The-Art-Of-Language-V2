{
  "topic_title": "011_Threat Hunting Methodology",
  "category": "002_Incident Response And Forensics - 002_Incident Response Lifecycle",
  "flashcards": [
    {
      "question_text": "According to NIST SP 800-61 Rev. 3, which of the following is a primary objective of the 'Detection and Analysis' phase in incident response, which threat hunting directly supports?",
      "correct_answer": "To determine the scope, impact, and root cause of an incident.",
      "distractors": [
        {
          "text": "To immediately eradicate all identified threats from the network.",
          "misconception": "Targets [phase confusion]: Confuses detection/analysis with eradication, which occurs later."
        },
        {
          "text": "To restore affected systems to their pre-incident state.",
          "misconception": "Targets [phase confusion]: Mixes detection with the recovery phase."
        },
        {
          "text": "To collect evidence for potential legal proceedings without further analysis.",
          "misconception": "Targets [analysis omission]: Overlooks the critical analysis step required to understand the incident."
        }
      ],
      "detailed_explanation": {
        "core_logic": "The 'Detection and Analysis' phase focuses on understanding the incident's nature, scope, and impact. Threat hunting, by proactively searching for undetected threats, directly aids this by providing early indicators and context, enabling a more thorough analysis.",
        "distractor_analysis": "The first distractor conflates detection with eradication. The second mixes detection with recovery. The third incorrectly suggests evidence collection without analysis, which is insufficient for understanding the incident.",
        "analogy": "Think of 'Detection and Analysis' as being a detective at a crime scene: you first identify what happened, who was involved, and the extent of the damage, before you start cleaning up or arresting suspects."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "NIST_SP_800_61",
        "INCIDENT_RESPONSE_PHASES"
      ]
    },
    {
      "question_text": "When employing a TTP-based threat hunting methodology, what is the primary advantage over solely relying on Indicators of Compromise (IoCs) like IP addresses or file hashes?",
      "correct_answer": "TTPs are more resilient to adversary changes and provide deeper context into attacker behavior.",
      "distractors": [
        {
          "text": "TTPs are easier to automate and require less skilled analysts.",
          "misconception": "Targets [automation misconception]: TTP-based hunting often requires more sophisticated analysis and understanding than simple IoC matching."
        },
        {
          "text": "IoCs are more effective against advanced persistent threats (APTs).",
          "misconception": "Targets [IoC effectiveness]: IoCs are brittle and easily bypassed by adaptable adversaries, unlike TTPs."
        },
        {
          "text": "TTPs are specific to individual malware families, ensuring precise identification.",
          "misconception": "Targets [TTP specificity]: TTPs describe broader techniques, not just specific malware signatures."
        }
      ],
      "detailed_explanation": {
        "core_logic": "TTPs (Tactics, Techniques, and Procedures) describe *how* adversaries operate, which are harder to change than specific IoCs like IP addresses or file hashes. Therefore, TTP-based hunting provides more durable detection and richer context, as adversaries must use techniques to achieve their goals.",
        "distractor_analysis": "The first distractor incorrectly assumes TTPs are easier to automate. The second reverses the effectiveness, as IoCs are less effective against APTs. The third mischaracterizes TTPs as specific to malware families rather than broader behaviors.",
        "analogy": "Hunting with IoCs is like looking for a specific car model that a thief used. Hunting with TTPs is like understanding the thief's *modus operandi* – how they break into houses, what tools they use, and their escape routes – which is much harder for them to change."
      },
      "code_snippets": [],
      "difficulty": "advanced",
      "question_type": "comparison",
      "bloom_level": "analyze",
      "prerequisites": [
        "MITRE_ATTACK",
        "INDICATORS_OF_COMPROMISE"
      ]
    },
    {
      "question_text": "Which threat hunting approach involves analyzing system logs and network traffic for deviations from normal, established baselines?",
      "correct_answer": "Anomaly-based hunting",
      "distractors": [
        {
          "text": "Signature-based hunting",
          "misconception": "Targets [detection method confusion]: Signature-based hunting looks for known malicious patterns, not deviations from normal."
        },
        {
          "text": "Hypothesis-driven hunting",
          "misconception": "Targets [hunting strategy confusion]: Hypothesis-driven hunting starts with a specific suspicion, not general anomaly detection."
        },
        {
          "text": "Threat intelligence-driven hunting",
          "misconception": "Targets [information source confusion]: This approach uses external threat feeds, not internal baselines."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Anomaly-based hunting establishes a baseline of normal system and network behavior. It then analyzes data for events or patterns that deviate significantly from this baseline, as these deviations may indicate malicious activity that signature-based methods would miss.",
        "distractor_analysis": "Signature-based hunting relies on known bad patterns. Hypothesis-driven hunting starts with a specific suspicion. Threat intelligence-driven hunting uses external feeds. Anomaly detection focuses on deviations from established norms.",
        "analogy": "Anomaly-based hunting is like a security guard noticing someone acting suspiciously in a normally quiet area, rather than just looking for known troublemakers."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "definition",
      "bloom_level": "understand",
      "prerequisites": [
        "THREAT_HUNTING_TYPES",
        "BEHAVIORAL_ANOMALY_DETECTION"
      ]
    },
    {
      "question_text": "In the context of threat hunting, what is the significance of the 'Pyramid of Pain' concept?",
      "correct_answer": "It illustrates that higher levels of adversary activity (like TTPs) are harder for attackers to change and therefore more valuable for detection.",
      "distractors": [
        {
          "text": "It prioritizes hunting for specific malware hashes over network indicators.",
          "misconception": "Targets [misinterpretation of hierarchy]: The pyramid ranks detection value, not specific IoC types."
        },
        {
          "text": "It suggests that threat intelligence feeds are the most effective hunting tool.",
          "misconception": "Targets [tool prioritization]: While intelligence is useful, the pyramid focuses on the *type* of adversary artifact, not the delivery mechanism."
        },
        {
          "text": "It defines the stages of incident response from detection to recovery.",
          "misconception": "Targets [scope confusion]: The Pyramid of Pain relates to adversary artifacts and detection value, not the IR lifecycle."
        }
      ],
      "detailed_explanation": {
        "core_logic": "The Pyramid of Pain, introduced by David Bianco, ranks adversary artifacts by the difficulty an attacker faces in changing them. The base (e.g., hashes, IPs) is easy to change, while the apex (TTPs) is the hardest. Therefore, hunting for TTPs provides more persistent detection capabilities because they are harder for adversaries to abandon.",
        "distractor_analysis": "The first distractor misinterprets the pyramid's focus on detection value over specific IoC types. The second incorrectly prioritizes threat intelligence feeds over the nature of the adversary artifact. The third confuses the pyramid with the incident response lifecycle.",
        "analogy": "The Pyramid of Pain is like understanding that it's easier for a burglar to change their getaway car (hash/IP) than to change their entire method of picking locks (TTP)."
      },
      "code_snippets": [],
      "difficulty": "advanced",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "PYRAMID_OF_PAIN",
        "MITRE_ATTACK"
      ]
    },
    {
      "question_text": "Which of the following is a key characteristic of a hypothesis-driven threat hunt?",
      "correct_answer": "It starts with a specific assumption or suspicion about potential adversary activity.",
      "distractors": [
        {
          "text": "It involves passively monitoring network traffic for any anomalies.",
          "misconception": "Targets [hunting approach confusion]: This describes passive monitoring or anomaly detection, not hypothesis-driven hunting."
        },
        {
          "text": "It relies solely on automated threat intelligence feeds to guide the investigation.",
          "misconception": "Targets [information source confusion]: While intelligence can inform hypotheses, the hunt itself is driven by a specific, human-generated suspicion."
        },
        {
          "text": "It aims to discover unknown threats without any preconceived notions.",
          "misconception": "Targets [hypothesis definition]: The core of this method is having a preconceived notion or hypothesis to test."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Hypothesis-driven threat hunting begins with a specific, testable assumption about adversary behavior, often informed by threat intelligence or observed anomalies. The hunt then proceeds to gather evidence to either confirm or refute this hypothesis, making it a targeted investigation.",
        "distractor_analysis": "The first distractor describes passive monitoring. The second incorrectly limits the hunt to automated feeds. The third contradicts the fundamental nature of a hypothesis, which is a preconceived idea.",
        "analogy": "Hypothesis-driven hunting is like a detective who, based on a tip, suspects a particular individual and then gathers evidence to prove or disprove that suspicion, rather than just looking for any crime."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "definition",
      "bloom_level": "understand",
      "prerequisites": [
        "THREAT_HUNTING_TYPES",
        "HYPOTHESIS_TESTING"
      ]
    },
    {
      "question_text": "When performing threat hunting, what is the purpose of establishing a 'baseline' of normal network and system activity?",
      "correct_answer": "To provide a reference point for identifying anomalous or potentially malicious behavior.",
      "distractors": [
        {
          "text": "To automatically block all traffic that deviates from the baseline.",
          "misconception": "Targets [automation/response confusion]: Baselines are for detection and analysis, not automatic blocking, which could cause false positives."
        },
        {
          "text": "To document the organization's security posture for compliance audits.",
          "misconception": "Targets [compliance confusion]: While baselines can support audits, their primary function in hunting is detection."
        },
        {
          "text": "To define the exact attack vectors used by adversaries.",
          "misconception": "Targets [detection scope confusion]: Baselines help identify *deviations*, not necessarily the specific attack vectors themselves."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Establishing a baseline of normal activity is crucial for anomaly-based threat hunting. This baseline serves as a benchmark against which all subsequent activity is compared. Deviations from this established norm are flagged as potential indicators of compromise, guiding further investigation.",
        "distractor_analysis": "The first distractor suggests automatic blocking, which is an inappropriate response to a baseline deviation. The second confuses the detection purpose with compliance documentation. The third incorrectly states baselines define attack vectors, rather than deviations from normal.",
        "analogy": "Establishing a baseline is like knowing what 'quiet' sounds like in a library. If suddenly there's a loud noise, you know something unusual has happened, prompting you to investigate."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "ANOMALY_DETECTION",
        "THREAT_HUNTING_BASICS"
      ]
    },
    {
      "question_text": "Which of the following best describes the role of threat intelligence in threat hunting?",
      "correct_answer": "It provides context, indicators, and TTPs that can inform hunting hypotheses and guide investigations.",
      "distractors": [
        {
          "text": "It replaces the need for manual threat hunting by automating detection.",
          "misconception": "Targets [automation misconception]: Threat intelligence enhances hunting but does not replace the need for human analysis and proactive searching."
        },
        {
          "text": "It only contains information about known malware signatures.",
          "misconception": "Targets [intelligence scope confusion]: Threat intelligence encompasses TTPs, vulnerabilities, and actor profiles, not just signatures."
        },
        {
          "text": "It is primarily used for post-incident forensic analysis.",
          "misconception": "Targets [intelligence application confusion]: While useful post-incident, intelligence is most valuable *proactively* during hunting."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Threat intelligence provides valuable insights into current and emerging threats, including adversary TTPs, IoCs, and actor profiles. This information is critical for developing informed hunting hypotheses and prioritizing searches, making threat hunting more efficient and effective.",
        "distractor_analysis": "The first distractor overstates the automation capabilities of threat intelligence. The second limits the scope of threat intelligence too narrowly. The third incorrectly restricts its use to post-incident activities.",
        "analogy": "Threat intelligence is like a detective receiving a bulletin about a known criminal gang's methods. This information helps the detective look for specific clues related to that gang's activities, rather than searching randomly."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "THREAT_INTELLIGENCE",
        "THREAT_HUNTING_BASICS"
      ]
    },
    {
      "question_text": "What is the primary goal of threat hunting in relation to an organization's security posture?",
      "correct_answer": "To proactively identify and neutralize threats that have bypassed existing security controls.",
      "distractors": [
        {
          "text": "To solely rely on automated security tools for threat detection.",
          "misconception": "Targets [automation reliance]: Threat hunting is a manual, proactive process that complements, rather than replaces, automated tools."
        },
        {
          "text": "To respond to security incidents after they have been formally reported.",
          "misconception": "Targets [proactive vs. reactive confusion]: Threat hunting is proactive, seeking threats *before* they are detected by automated systems or reported."
        },
        {
          "text": "To implement new security controls based on detected threats.",
          "misconception": "Targets [hunting vs. remediation confusion]: While hunting findings inform remediation, the primary goal is detection and neutralization, not implementation of controls."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Threat hunting's core purpose is to proactively search for advanced threats that may have evaded automated defenses. By actively seeking out these hidden adversaries, organizations can neutralize them before significant damage occurs, thereby strengthening their overall security posture.",
        "distractor_analysis": "The first distractor suggests reliance on automation, which is contrary to the proactive, manual nature of hunting. The second confuses hunting's proactive role with reactive incident response. The third misattributes the primary goal, which is detection and neutralization, not control implementation.",
        "analogy": "Threat hunting is like a security guard actively patrolling a building, looking for intruders who might have slipped past the main doors and alarms, rather than just waiting for an alarm to sound."
      },
      "code_snippets": [],
      "difficulty": "foundational",
      "question_type": "definition",
      "bloom_level": "understand",
      "prerequisites": [
        "THREAT_HUNTING_BASICS",
        "SECURITY_CONTROLS"
      ]
    },
    {
      "question_text": "Which of the following is an example of a 'Tactic' within the MITRE ATT&CK framework, relevant to threat hunting?",
      "correct_answer": "Credential Access",
      "distractors": [
        {
          "text": "Exploiting a specific CVE-2023-XXXX vulnerability",
          "misconception": "Targets [Tactic vs. Technique/Vulnerability confusion]: This is a specific technique or vulnerability, not a broad tactic."
        },
        {
          "text": "A phishing email with a malicious attachment",
          "misconception": "Targets [Tactic vs. Procedure/Method confusion]: This describes a method or procedure, not a high-level tactic."
        },
        {
          "text": "The IP address 192.168.1.100",
          "misconception": "Targets [Tactic vs. IoC confusion]: This is an Indicator of Compromise (IoC), not a tactic."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Tactics in the MITRE ATT&CK framework represent the adversary's high-level goals or reasons for performing an action (e.g., gaining initial access, executing code, maintaining persistence). 'Credential Access' is a tactic focused on stealing account or login information.",
        "distractor_analysis": "The first distractor is a specific vulnerability/technique. The second describes a method/procedure. The third is a simple IoC. 'Credential Access' is a recognized tactic in the ATT&CK framework.",
        "analogy": "In a heist movie, 'Credential Access' is like the goal of stealing the master keycard, whereas 'phishing email' is *how* they might try to get it, and '192.168.1.100' is like the specific getaway car's license plate."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "definition",
      "bloom_level": "understand",
      "prerequisites": [
        "MITRE_ATTACK",
        "TACTICS_TECHNIQUES_PROCEDURES"
      ]
    },
    {
      "question_text": "What is the primary benefit of using threat hunting playbooks?",
      "correct_answer": "To provide structured, repeatable steps for investigating specific types of threats or hypotheses.",
      "distractors": [
        {
          "text": "To automatically block all identified malicious activities.",
          "misconception": "Targets [playbook vs. automation confusion]: Playbooks guide investigation and response actions, they don't inherently automate blocking."
        },
        {
          "text": "To replace the need for human analysts in threat detection.",
          "misconception": "Targets [automation misconception]: Playbooks are tools for analysts, enhancing their capabilities, not replacing them."
        },
        {
          "text": "To generate comprehensive incident reports without analyst input.",
          "misconception": "Targets [playbook scope confusion]: Playbooks assist in the investigation process, but final reporting still requires analyst input and synthesis."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Threat hunting playbooks offer a standardized approach to investigating specific threats or hypotheses. They provide a sequence of actions, queries, and tools to use, ensuring consistency and efficiency, and helping analysts systematically gather evidence and reach conclusions.",
        "distractor_analysis": "The first distractor suggests automatic blocking, which is an outcome of response, not the playbook's primary function. The second incorrectly claims playbooks replace analysts. The third overstates the automation of reporting.",
        "analogy": "A threat hunting playbook is like a recipe for investigating a specific type of crime: it lists the ingredients (data sources), the steps (queries, analysis), and the expected outcome (confirmation or refutation of hypothesis)."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "procedure",
      "bloom_level": "apply",
      "prerequisites": [
        "THREAT_HUNTING_PLAYBOOKS",
        "INCIDENT_RESPONSE_PROCEDURES"
      ]
    },
    {
      "question_text": "When analyzing logs for signs of lateral movement, which of the following would be a strong indicator?",
      "correct_answer": "Unusual remote login activity (e.g., RDP, SSH) from a compromised host to other internal systems.",
      "distractors": [
        {
          "text": "A single user accessing a file share from their workstation.",
          "misconception": "Targets [normal activity confusion]: Standard file share access is typical user behavior, not lateral movement."
        },
        {
          "text": "Successful antivirus scan completion on a server.",
          "misconception": "Targets [security control confusion]: Antivirus scans are security measures, not indicators of lateral movement."
        },
        {
          "text": "A user reporting a slow internet connection.",
          "misconception": "Targets [symptom confusion]: Slow internet can have many causes unrelated to lateral movement."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Lateral movement involves an adversary moving from one compromised system to others within a network. Unusual remote login activity from a compromised host to other internal systems is a classic indicator of this behavior, as attackers attempt to expand their foothold.",
        "distractor_analysis": "The first distractor describes normal user activity. The second describes a security control's function. The third describes a vague symptom with many potential causes. Unusual remote logins are a direct sign of an attacker trying to move laterally.",
        "analogy": "Lateral movement is like a burglar, after breaking into one house, using the keys they found inside to enter other houses on the same street. Unusual key usage from an already compromised location is the tell-tale sign."
      },
      "code_snippets": [],
      "difficulty": "advanced",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "LATERAL_MOVEMENT",
        "LOG_ANALYSIS"
      ]
    },
    {
      "question_text": "What is the primary purpose of threat hunting in the context of NIST Cybersecurity Framework (CSF) 2.0?",
      "correct_answer": "To enhance the 'Detect' function by proactively identifying threats that automated systems might miss.",
      "distractors": [
        {
          "text": "To fulfill the 'Respond' function by eradicating identified threats.",
          "misconception": "Targets [function confusion]: While hunting informs response, its primary role is in detection, not eradication itself."
        },
        {
          "text": "To establish the initial security controls outlined in the 'Protect' function.",
          "misconception": "Targets [function confusion]: Threat hunting is a proactive measure *after* initial protections are in place, not for establishing them."
        },
        {
          "text": "To perform post-incident reviews as part of the 'Recover' function.",
          "misconception": "Targets [function confusion]: Hunting is proactive and ongoing, distinct from the reactive post-incident activities of recovery."
        }
      ],
      "detailed_explanation": {
        "core_logic": "NIST CSF 2.0 emphasizes integrating cybersecurity risk management with incident response. Threat hunting directly supports the 'Detect' function by proactively searching for threats that may have bypassed preventative controls, thereby improving the organization's ability to identify and understand potential cybersecurity events early.",
        "distractor_analysis": "The first distractor conflates hunting's detection role with the 'Respond' function. The second incorrectly places hunting within the 'Protect' function. The third misaligns hunting with the 'Recover' function's post-incident focus.",
        "analogy": "In the NIST CSF, threat hunting is like having a vigilant security guard actively searching for hidden dangers within a building (Detect), rather than just relying on the locks and alarms (Protect) or cleaning up after a break-in (Respond/Recover)."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "NIST_CSF",
        "THREAT_HUNTING_BASICS"
      ]
    },
    {
      "question_text": "Which of the following is a common data source utilized in threat hunting for detecting suspicious process execution?",
      "correct_answer": "Endpoint Detection and Response (EDR) logs",
      "distractors": [
        {
          "text": "Publicly available weather data",
          "misconception": "Targets [data relevance confusion]: Weather data is irrelevant to detecting suspicious process execution on endpoints."
        },
        {
          "text": "Customer support call logs",
          "misconception": "Targets [data relevance confusion]: While potentially useful for other analyses, call logs are not primary for process execution monitoring."
        },
        {
          "text": "Social media trending topics",
          "misconception": "Targets [data relevance confusion]: Social media trends are generally not direct indicators of internal process execution anomalies."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Endpoint Detection and Response (EDR) solutions are specifically designed to monitor endpoint activity, including process creation, network connections, and file modifications. Their logs provide rich data for threat hunters seeking to identify suspicious process execution that might indicate malware or unauthorized activity.",
        "distractor_analysis": "The distractors represent irrelevant data sources. Weather data, customer support logs, and social media trends do not provide the necessary telemetry for analyzing process execution on endpoints.",
        "analogy": "Looking for suspicious process execution using EDR logs is like checking the security camera footage inside a building to see who is running around suspiciously. The other options are like checking the weather forecast or customer complaints, which won't show you internal activity."
      },
      "code_snippets": [],
      "difficulty": "foundational",
      "question_type": "definition",
      "bloom_level": "understand",
      "prerequisites": [
        "EDR",
        "LOG_ANALYSIS"
      ]
    },
    {
      "question_text": "What is the main challenge when using Indicators of Compromise (IoCs) for threat hunting, as highlighted by concepts like the Pyramid of Pain?",
      "correct_answer": "IoCs, especially at the lower levels of the pyramid (like hashes and IPs), are easily changed by adversaries, making detection brittle.",
      "distractors": [
        {
          "text": "IoCs are too complex to analyze without advanced machine learning.",
          "misconception": "Targets [complexity misconception]: Many IoCs are straightforward identifiers, though correlating them can be complex."
        },
        {
          "text": "There is a lack of publicly available IoCs for threat hunting.",
          "misconception": "Targets [availability misconception]: Numerous sources provide IoCs; the challenge is their effectiveness and relevance."
        },
        {
          "text": "IoCs only identify known threats and cannot detect novel attacks.",
          "misconception": "Targets [scope misconception]: While IoCs are based on known compromises, the challenge is their *persistence* against evolving threats, not their inability to detect novel attacks per se (though they are poor at it)."
        }
      ],
      "detailed_explanation": {
        "core_logic": "The Pyramid of Pain illustrates that adversaries can change lower-level IoCs (e.g., IP addresses, file hashes) relatively easily to evade detection. This makes hunting based solely on these IoCs less effective over time, as the indicators quickly become outdated. Higher-level artifacts like TTPs are harder to change and thus provide more durable detection.",
        "distractor_analysis": "The first distractor overstates the complexity of IoC analysis. The second incorrectly claims a lack of availability. The third mischaracterizes the primary challenge as detecting novel attacks, rather than the ephemeral nature of the IoCs themselves.",
        "analogy": "Relying solely on IoCs like IP addresses is like trying to catch a criminal by their license plate number – they can easily switch cars (change the IP/hash) to avoid being caught."
      },
      "code_snippets": [],
      "difficulty": "advanced",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "INDICATORS_OF_COMPROMISE",
        "PYRAMID_OF_PAIN"
      ]
    },
    {
      "question_text": "Which of the following describes a 'Technique' in the context of the MITRE ATT&CK framework, relevant for threat hunting?",
      "correct_answer": "Specific methods adversaries use to achieve a tactical goal, such as 'T1059: Command and Scripting Interpreter'.",
      "distractors": [
        {
          "text": "The overall objective of an attack, like 'Data Exfiltration'.",
          "misconception": "Targets [Technique vs. Tactic confusion]: 'Data Exfiltration' is a Tactic, representing a goal, not a specific method."
        },
        {
          "text": "A unique identifier for a known malicious file, like a SHA256 hash.",
          "misconception": "Targets [Technique vs. IoC confusion]: This is an Indicator of Compromise (IoC), not a technique."
        },
        {
          "text": "The name of a specific threat actor group, such as 'APT29'.",
          "misconception": "Targets [Technique vs. Actor confusion]: This refers to the adversary group, not their methods."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Techniques in the MITRE ATT&CK framework describe the specific ways adversaries achieve their goals (Tactics). For example, 'Command and Scripting Interpreter' (T1059) details *how* an adversary might execute commands or scripts on a system, which is a crucial detail for threat hunters to look for.",
        "distractor_analysis": "The first distractor describes a Tactic. The second describes an IoC. The third describes an adversary group. 'Command and Scripting Interpreter' is a specific, actionable method used by adversaries, fitting the definition of a Technique.",
        "analogy": "If the Tactic is 'Stealing Valuables', a Technique might be 'Using a crowbar to pry open a window' (T1059 could be analogous to using a specific tool or method to achieve a goal)."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "definition",
      "bloom_level": "understand",
      "prerequisites": [
        "MITRE_ATTACK",
        "TACTICS_TECHNIQUES_PROCEDURES"
      ]
    }
  ],
  "generation_metadata": {
    "model": "google/gemini-2.5-flash-lite",
    "num_generated": 15,
    "temperature": 0.1,
    "web_citations": [],
    "research_method": "openrouter_web_plugin",
    "search_query": "011_Threat Hunting Methodology 002_Incident Response And Forensics best practices",
    "latency_ms": 23365.069
  },
  "timestamp": "2026-01-18T12:57:29.963209"
}