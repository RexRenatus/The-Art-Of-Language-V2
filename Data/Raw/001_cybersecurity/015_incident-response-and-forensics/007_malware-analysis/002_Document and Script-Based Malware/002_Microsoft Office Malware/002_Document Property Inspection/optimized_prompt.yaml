version: '2.0'
metadata:
  topic_title: Document Property Inspection
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: 002_Incident Response And Forensics
    level_3_subdomain: 007_Malware Analysis
    level_4_entry_domain: 006_Document and Script-Based Malware
    level_5_entry_subdomain: Microsoft Office Malware
    level_6_topic: Document Property Inspection
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 015_incident-response-and-forensics
    subdomain: 007_malware-analysis
  exa_sources: []
  voting:
    consensus_reached: false
    approval_percentage: 0.14
    total_voters: 7
  generation_timestamp: '2026-01-18T14:06:40.378359'
learning_objectives:
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
active_learning:
  discussion_prompt: In a group discussion, debate the strengths and limitations of relying on document metadata (e.g., timestamps
    and author fields) for attributing Office malware attacks. Reference real-world examples from MITRE ATT&CK and SANS forensics
    resources. How might attackers manipulate these properties, and what countermeasures can analysts employ?
  peer_teaching: Explain the key concepts to a partner without using technical jargon.
  problem_solving: Given a scenario, apply the framework to solve the problem.
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol: 'Generate distractors based on: 1) Common errors (e.g., ''exiftool'' instead of ''olevba'' for Office
    VBA); 2) Superficially similar terms (e.g., ''SummaryInformation'' vs. ''DocumentSummaryInformation''); 3) Anti-forensic
    red herrings (e.g., normal vs. manipulated timestamps); 4) Irrelevant physical forensics (e.g., ''paper type'' as distractor
    for digital metadata). Ensure 70% of cards are MCQ-style.'
system_prompt: 'You are an expert flashcard generator for cybersecurity education, specializing in Malware Analysis for Microsoft
  Office Malware under the topic ''Document Property Inspection''. Topic Hierarchy: Cybersecurity > 002_Incident Response
  And Forensics > 007_Malware Analysis > 006_Document and Script-Based Malware > Microsoft Office Malware > Document Property
  Inspection.


  Generate 50 high-quality flashcards optimized for spaced repetition and Bloom''s Taxonomy. Cover these learning objectives:
  [INSERT learning_objectives ARRAY HERE]. Incorporate active learning elements (e.g., reference discussion prompts in explanations).
  Use 4-layer scaffolding: [INSERT scaffolding OBJECT HERE].


  Key content focus (digital only, no physical forensics): Metadata (author, timestamps, revisions); OLE streams (SummaryInformation,
  DocumentSummaryInformation); macros/VBA; tools (oledump.py, olevba, oletools); standards (NIST IR 7617, MITRE ATT&CK T1204.002,
  SANS). Emphasize safe inspection, hashing, chain of custody.


  Follow this exact schema for each flashcard in a JSON array:

  [{"front": "...", "back": "...", "explanation": "...", "distractors": ["...", "..."], "metadata": {"bloom_level": "...",
  "scaffolding_layer": "...", "difficulty": "..."}}]


  Adhere to flashcard_schema: [INSERT flashcard_schema OBJECT HERE]. Ensure variety: 30% remember/understand, 30% apply/analyze,
  40% evaluate/create. Questions must be active and testable.'
