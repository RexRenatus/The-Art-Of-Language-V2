version: '2.0'
metadata:
  topic_title: Metadata Scrubbing
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: 002_Incident Response And Forensics
    level_3_subdomain: Digital Forensics
    level_4_entry_domain: 013_Anti-Forensics and Countermeasures
    level_5_entry_subdomain: Data Destruction Methods
    level_6_topic: Metadata Scrubbing
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 015_incident-response-and-forensics
    subdomain: 005_digital-forensics
  exa_sources: []
  voting:
    consensus_reached: true
    approval_percentage: 0.83
    total_voters: 7
  generation_timestamp: '2026-01-18T13:49:53.608693'
learning_objectives:
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
active_learning:
  discussion_prompt: In a forensic investigation, should defense teams routinely scrub metadata from evidence files before
    court submission? Argue the pros (e.g., privacy protection, anti-forensics evasion) and cons (e.g., evidence tampering
    allegations, chain of custody issues) using real-world examples like Bellingcat investigations.
  peer_teaching: 'Students pair up: Partner A teaches Partner B how to inspect and scrub metadata from a sample file (e.g.,
    JPEG with EXIF data) using ExifTool or MAT2, demonstrating commands and verification steps; then switch roles and provide
    feedback.'
  problem_solving: 'Provide a ''leaked'' sample image or PDF containing embedded PII (e.g., GPS location, author, timestamps).
    Students must: 1) Identify sensitive metadata risks, 2) Scrub it using a tool, 3) Verify removal, and 4) Discuss forensic
    countermeasures like timeline analysis if scrubbing fails.'
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol: '1) Base on voter priorities/misconceptions: e.g., ''Metadata scrubbing destroys file content'' (vs.
    preserves it); ''All metadata is always fully removable'' (vs. limitations like carving); ''NIST SP 800-88 mandates scrubbing''
    (vs. supports confidentiality indirectly). 2) Ensure plausibility (partial truths). 3) Vary difficulty: easy (superficial
    errors), medium (technical mix-ups), hard (subtle anti-forensics nuances). 4) No more than 4 options total per MCQ.'
system_prompt: 'You are an expert flashcard generator for cybersecurity education, specializing in Digital Forensics (Domain:
  002_Incident Response And Forensics > Digital Forensics > 013_Anti-Forensics and Countermeasures > Data Destruction Methods
  > Metadata Scrubbing). Use the provided learning objectives, active learning activities, 4-layer scaffolding, and flashcard
  schema to create optimized, spaced-repetition-friendly flashcards.


  Topic Context: Metadata scrubbing removes sensitive metadata (e.g., EXIF GPS, author, timestamps) from files (JPEG, PDF,
  etc.) to evade forensics, distinct from NIST SP 800-88 full sanitization. Tools: ExifTool, MAT2. Limitations: Residual data
  recoverable via carving. Big Picture: Prevents attribution in investigations; links to timestomping, file wiping.


  Incorporate pedagogy: Align to Bloom''s (1-2 per level), scaffold layers, active elements (e.g., scenario questions mimicking
  discussions/problems). Voter consensus: 82.9% approval emphasizes tools/examples/anti-forensics.


  Output ONLY a JSON array of flashcards, each matching the exact schema: {''front'': str, ''back'': str, ''explanation'':
  str, ''type'': ''Cloze|MCQ'', ''bloom_level'': str, ''distractors'': []}. Generate 25 flashcards covering all objectives/layers.
  Ensure distractors follow protocol. No additional text.'
