version: '2.0'
metadata:
  topic_title: Secondary Evidence Assessment
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: Security And Risk Management
    level_3_subdomain: Investigation Types
    level_4_entry_domain: Investigation Standards and Compliance
    level_5_entry_subdomain: Evidence Standards Investigation
    level_6_topic: Secondary Evidence Assessment
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 001_security-and-risk-management
    subdomain: 002_investigation-types
  exa_sources: []
  voting:
    consensus_reached: true
    approval_percentage: 0.7
    total_voters: 7
  generation_timestamp: '2026-01-01T10:46:43.634717'
learning_objectives:
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
active_learning:
  discussion_prompt: In a cybersecurity audit, debate the reliability of secondary evidence (e.g., third-party certifications
    like SOC 2 reports) versus primary evidence (e.g., live system inspections or personnel interviews). Use NIST SP 800-53
    control families (e.g., AU for audit and accountability) to argue pros, cons, and scenarios where secondary evidence suffices
    or falls short. Consider scalability for supply chain risk management.
  peer_teaching: Explain the key concepts to a partner without using technical jargon.
  problem_solving: Given a scenario, apply the framework to solve the problem.
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol: 'Generate 3 plausible distractors per MCQ: 1) Common misconception (e.g., ''Secondary evidence is always
    less reliable'' â€“ ignores context); 2) Partial truth (e.g., confuses with primary); 3) Extreme/opposite (e.g., ''No verification
    needed''). Ensure 60-70% MCQ, rest cloze/short answer. Balance coverage: 20% per Bloom''s level, 25% per layer.'
system_prompt: 'You are an expert flashcard generator for cybersecurity education, specializing in ''Secondary Evidence Assessment''
  (Topic Hierarchy: Cybersecurity > Security And Risk Management > Investigation Types > Investigation Standards and Compliance
  > Evidence Standards Investigation > Secondary Evidence Assessment). Generate 50 high-quality flashcards optimized for Anki/Spaced
  Repetition using university pedagogy: Bloom''s Taxonomy (cover all 6 objectives provided), active learning hooks (scenarios
  from activities), 4-layer scaffolding (build from foundation to integration), and prior/big-picture context (NIST 800-30,
  CSF 2.0 Govern, scalable assurance).


  Core Content: [Insert full research context, definitions, NIST 800-30 steps, CSF 2.0 relevance (e.g., GV for policies/reports),
  800-53 examples]. Prior knowledge: Primary evidence, basic risk assessment.


  Learning Objectives: [List all 6]. Scaffolding: [List all layers/prior/big picture]. Active Learning: Embed scenario/discussion
  elements.


  Output EXACTLY 50 flashcards in JSON array: [{''front'': ''...'', ''back'': {''answer'': ''...'', ''explanation'': ''...'',
  ''references'': ''...'', ''objective_link'': ''...'', ''layer_link'': ''...''}}, ...]. Follow schema precisely: 60% MCQ
  (4 opts A-D, mark correct), distractors plausible/misconception-based. Balance: ~8 per objective, ~12 per layer. Questions
  progressive (Layer1 simple recall -> Layer4 synthesis). Action-verb aligned, assessable. No adult/offensive content.'
