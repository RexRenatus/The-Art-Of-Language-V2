version: '2.0'
metadata:
  topic_title: Security Testing in Testing Phase
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: Security And Risk Management
    level_3_subdomain: Security Policy Development
    level_4_entry_domain: Policy Implementation and Integration
    level_5_entry_subdomain: SDLC Integration
    level_6_topic: Security Testing in Testing Phase
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 001_security-and-risk-management
    subdomain: 011_security-policy-development
  exa_sources: []
  voting:
    consensus_reached: true
    approval_percentage: 1.0
    total_voters: 7
  generation_timestamp: '2026-01-01T12:54:47.433376'
learning_objectives:
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
active_learning:
  discussion_prompt: Compare SAST, DAST, and IAST. When in the SDLC testing phase would each be most effective, and what are
    the trade-offs (e.g., coverage vs. false positives)? Debate using OWASP Top 10 examples like Injection or Broken Authentication
    to spark critical thinking on integration vs. dedicated testing.
  peer_teaching: Explain the key concepts to a partner without using technical jargon.
  problem_solving: Given a scenario, apply the framework to solve the problem.
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol: 'Generate 3 plausible distractors per MCQ: 1) Common misconception (e.g., ''SAST tests running code''
    instead of static), 2) Partial truth/mix-up (e.g., confuse DAST with SAST timing), 3) Extreme/edge case (e.g., ''Pen testing
    replaces all automated scans''). Base on voter notes (e.g., automated vs. manual), research (OWASP Top 10), ensure 1 correct
    answer.'
system_prompt: 'You are an expert flashcard generator for cybersecurity education, specializing in university-level pedagogy
  (Bloom''s Taxonomy, active learning, scaffolding). Generate high-quality flashcards for the topic ''Security Testing in
  Testing Phase'' (Hierarchy: Cybersecurity > Security And Risk Management > Security Policy Development > Policy Implementation
  and Integration > SDLC Integration > Security Testing in Testing Phase).


  Core Content (from research, completed OWASP WSTG): Security Testing evaluates security features in SDLC testing phase.
  Key concepts: Vulnerability (weakness), Threat (danger), Risk (likelihood x impact). Types: SAST (static code, early/non-runtime),
  DAST (dynamic runtime attacks), IAST (hybrid instrumentation), Pen Testing (manual simulated attacks), Vuln Scanning (automated
  known issues), SCA (third-party libs). OWASP WSTG Categories (full): Information Gathering, Configuration/Deployment Management,
  Identity Management, Authentication, Authorization, Session Management, Input Validation, Error Handling, Cryptography,
  Business Logic, Client-Side Testing, API Testing. Tools: OWASP ZAP/Burp (DAST), SonarQube (SAST). Integrate with OWASP Top
  10 (e.g., Injection via Input Validation). Sources: OWASP WSTG (https://owasp.org/www-project-web-security-testing-guide/),
  NIST SP 800-115 (https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-115.pdf), OWASP Top 10 (https://owasp.org/Top10/).


  Use these EXACT learning objectives: [insert learning_objectives array here].

  Incorporate active learning for context: [insert active_learning object here].

  Follow 4-layer scaffolding: [insert scaffolding array here].


  Generate 40-60 flashcards covering all layers/Bloom''s (prioritize higher levels), ensuring completeness (full OWASP coverage,
  voter priorities like SAST/DAST trade-offs, peer misconceptions).

  Output STRICTLY as JSON array per schema: [insert flashcard_schema.structure, distractor_protocol, etc. here]. No extra
  text.'
