version: '2.0'
metadata:
  topic_title: Training Effectiveness Measurement
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: Security And Risk Management
    level_3_subdomain: Legal, Regulatory, and Compliance
    level_4_entry_domain: Personnel Security and Ethics
    level_5_entry_subdomain: Security Awareness and Training Compliance
    level_6_topic: Training Effectiveness Measurement
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 001_security-and-risk-management
    subdomain: 003_legal-regulatory-and-compliance
  exa_sources: []
  voting:
    consensus_reached: true
    approval_percentage: 1.0
    total_voters: 7
  generation_timestamp: '2026-01-01T11:03:43.377837'
learning_objectives:
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
active_learning:
  discussion_prompt: Evaluate the limitations of using only quantitative metrics (e.g., completion rates, test scores) for
    measuring cybersecurity training effectiveness. Propose a balanced set of quantitative and qualitative metrics based on
    NIST SP 800-50 Rev. 1, and debate their pros and cons in a group setting to encourage critical thinking about real-world
    applicability and misconceptions like over-relying on test scores.
  peer_teaching: Explain the key concepts to a partner without using technical jargon.
  problem_solving: Given a scenario, apply the framework to solve the problem.
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol:
    mcq_format: 4 options (1 correct, 3 distractors)
    distractor_rules: 1. Common misconception (e.g., 'Training effectiveness is only measured by test scores'); 2. Partial
      truth (e.g., 'Quantitative metrics alone suffice'); 3. Unrelated/plausible alternative (e.g., 'Focus only on executive
      training'); Ensure distractors are realistic based on voter-noted misconceptions like over-relying on quant metrics.
    quantity: Generate 70% MCQ with distractors, 30% open-ended for higher Bloom's
system_prompt: 'You are an expert flashcard generator for cybersecurity education, specializing in Training Effectiveness
  Measurement (Topic Hierarchy: Cybersecurity > Security And Risk Management > Legal, Regulatory, and Compliance > Personnel
  Security and Ethics > Security Awareness and Training Compliance > Training Effectiveness Measurement).


  Generate 75 high-quality flashcards using the provided schema. Base content strictly on:

  - Scaffolding layers (Layer 1 Foundation to Layer 4 Integration).

  - Learning objectives across Bloom''s Taxonomy.

  - NIST SP 800-50 Rev. 1 (full CPLP life cycle: Plan/Develop, Implement, Evaluate, Improve; https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-50r1.pdf),
  Kirkpatrick model, CISSP domains.

  - Key sources: NIST SP 800-50 Rev. 1; Kirkpatrick Four Levels (https://www.kirkpatrickpartners.com/The-New-World-of-Kirkpatrick-Four-Levels/);
  CISSP Official CBK.


  Incorporate active learning: Include 10% of cards as discussion/peer-teach prompts (e.g., ''Debate: Why avoid only quant
  metrics?''). Ensure progressive scaffolding in card sequencing.


  Output format: JSON array of objects, each: {''front'': ''Question'', ''back'': {''answer'': ''...'', ''explanation'': ''...'',
  ''bloom_level'': ''...'', ''layer'': ''1-4'', ''references'': ''...''}}, MCQs with options array in front.


  Balance: 20% Remember/Understand (Layer 1-2), 40% Apply/Analyze (Layer 2-3), 40% Evaluate/Create (Layer 3-4). Use distractor
  protocol for MCQs. Make explanations pedagogical, tying to real-world application and misconceptions.'
