<?xml version="1.0" encoding="UTF-8"?>
<topic_prompt version="2.0">
  <metadata>
    <topic_title>AI bias detection and mitigation</topic_title>
    <hierarchy>
      <category>Cybersecurity</category>
      <domain>Security And Risk Management</domain>
      <subdomain>Security Control Frameworks</subdomain>
      <entry_domain>Specialized Control Domains</entry_domain>
      <entry_subdomain>AI/ML Security Controls</entry_subdomain>
    </hierarchy>
    <voting_summary>
      <consensus>True</consensus>
      <approval>100.0%</approval>
      <voters>7</voters>
    </voting_summary>
    <generation_timestamp>2026-01-01T12:23:23.530935</generation_timestamp>
  </metadata>
  <learning_objectives level="bloom_taxonomy">
    <objective level="remember" measurable="true" verbs="define">Define key terminology</objective>
    <objective level="understand" measurable="true" verbs="explain">Explain core concepts</objective>
    <objective level="apply" measurable="true" verbs="apply">Apply knowledge to scenarios</objective>
    <objective level="analyze" measurable="true" verbs="analyze">Analyze relationships</objective>
  </learning_objectives>
  <active_learning>
    <discussion_prompt>In a group discussion, analyze a real-world cybersecurity case of AI bias (e.g., biased facial recognition in surveillance systems leading to discriminatory threat detection). Debate the primary sources of bias, evaluate mitigation strategies using fairness metrics like demographic parity and equal opportunity, and propose how NIST AI RMF's Govern and Manage functions could prevent recurrence. Support arguments with socio-technical considerations.</discussion_prompt>
    <peer_teaching>Explain the key concepts to a partner without using technical jargon.</peer_teaching>
    <problem_solving>Given a scenario, apply the framework to solve the problem.</problem_solving>
  </active_learning>
  <scaffolding>
    <layer level="1" name="Foundation">
      <focus>Basic terminology and definitions</focus>
      <content/>
    </layer>
    <layer level="2" name="Components">
      <focus>Framework components and structure</focus>
      <content/>
    </layer>
    <layer level="3" name="Implementation">
      <focus>Practical implementation steps</focus>
      <content/>
    </layer>
    <layer level="4" name="Integration">
      <focus>Advanced integration and optimization</focus>
      <content/>
    </layer>
  </scaffolding>
  <flashcard_generation>
    <output_schema>
      <field name="question" type="string"/>
      <field name="correct_answer" type="string"/>
      <field name="distractors" type="[{'text': 'string', 'explanation': 'string'}]"/>
      <field name="explanation" type="string"/>
      <field name="bloom_level" type="enum"/>
      <field name="topic_hierarchy" type="object"/>
    </output_schema>
    <distractor_protocol>
      <step number="1">Identify common misconceptions about the topic</step>
      <step number="2">Create plausible but incorrect alternatives</step>
      <step number="3">Ensure distractors are similar in length and complexity</step>
      <step number="4">Avoid obviously wrong answers</step>
      <step number="5">Include partial truths that require deeper understanding</step>
    </distractor_protocol>
    <system_prompt>You are an expert flashcard generator specializing in cybersecurity education, particularly AI/ML Security Controls. Generate 40 high-quality flashcards on 'AI bias detection and mitigation' (Topic Hierarchy: Cybersecurity &gt; Security And Risk Management &gt; Security Control Frameworks &gt; Specialized Control Domains &gt; AI/ML Security Controls &gt; AI bias detection and mitigation). Use the provided research context (AI bias definition/sources: data/algorithmic/human; socio-technical approach; NIST AI RMF full functions: Govern-policies/accountability; Map-risk identification; Measure-fairness metrics e.g. demographic parity, equal opportunity; Manage-mitigation/response), voter-completed details (fairness metrics, pre/in/post-processing mitigations: resampling/regularization/thresholding), and assume prior knowledge of basic ML/security risks.
Incorporate:
- Learning objectives: [insert array above]
- Active learning: Tie flashcards to discussion/peer teaching/problem-solving (e.g., scenario cards for exercises).
- Scaffolding: Distribute evenly: 10 Layer 1 (foundation), 10 Layer 2 (components/NIST), 10 Layer 3 (implementation/techniques), 10 Layer 4 (integration/cybersecurity).
- Bloom's progression: 8 Remember/Understand, 12 Apply/Analyze, 12 Evaluate, 8 Create (advanced scenario/design cards).
- Flashcard schema: Front (question w/ format variety, tag w/ Bloom's level e.g. 'Bloom: Analyze' and layer e.g. 'Layer 3'); Back (answer, explanation, distractors explained if MCQ, links to objectives/layers).
Output as JSON array of 40 objects: [{'id':1, 'bloom_level':'Analyze', 'scaffolding_layer':'Layer 2', 'type':'MCQ', 'front':'...', 'back':{'answer':'...', 'explanation':'...', 'distractors':[{'option':'...', 'why_wrong':'...'}], 'links':['Objective 4', 'Peer teaching: NIST functions']}}]. Ensure distractors are plausible per protocol. Cards must be optimized for active recall, spaced repetition, and university pedagogy (scaffolding from basics to integration).</system_prompt>
  </flashcard_generation>
</topic_prompt>