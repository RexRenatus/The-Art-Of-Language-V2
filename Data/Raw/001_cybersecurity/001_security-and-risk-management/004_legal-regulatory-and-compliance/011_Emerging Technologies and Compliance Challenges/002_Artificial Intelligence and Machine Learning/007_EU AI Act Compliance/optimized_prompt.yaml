version: '2.0'
metadata:
  topic_title: EU AI Act Compliance
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: Security And Risk Management
    level_3_subdomain: Legal, Regulatory, and Compliance
    level_4_entry_domain: Emerging Technologies and Compliance Challenges
    level_5_entry_subdomain: Artificial Intelligence and Machine Learning
    level_6_topic: EU AI Act Compliance
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 001_security-and-risk-management
    subdomain: 003_legal-regulatory-and-compliance
  exa_sources: []
  voting:
    consensus_reached: true
    approval_percentage: 1.0
    total_voters: 7
  generation_timestamp: '2026-01-01T10:53:25.420938'
learning_objectives:
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
active_learning:
  discussion_prompt: 'In a group discussion, debate the classification of generative AI tools like ChatGPT: Should they always
    be treated as High-Risk, or is the GPAI framework sufficient? Use examples of potential harms and benefits to argue positions,
    referencing Act definitions and obligations.'
  peer_teaching: Explain the key concepts to a partner without using technical jargon.
  problem_solving: Given a scenario, apply the framework to solve the problem.
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol: 'Create 3 plausible distractors per MCQ: 1 from common misconceptions (e.g., ''All generative AI is
    High-Risk'' vs. GPAI), 1 from similar categories (e.g., Limited vs. Minimal obligations), 1 from unrelated regs (e.g.,
    GDPR fine amounts). Ensure distractors are realistic based on voter-noted misconceptions.'
system_prompt: 'You are an expert EU AI Act compliance educator, synthesizing university-level flashcards for Cybersecurity
  > Security And Risk Management > Legal, Regulatory, and Compliance > Emerging Technologies and Compliance Challenges > Artificial
  Intelligence and Machine Learning > EU AI Act Compliance. Ensure 100% completeness: Cover Unacceptable (banned), High-Risk
  (full Provider/Deployer obligations: risk mgmt, data governance, docs, record-keeping, transparency, oversight, accuracy/robustness/cybersec),
  Limited (transparency: chatbots/emotion/deepfakes), Minimal (voluntary), GPAI (transparency, systemic risks, incidents),
  timelines, enforcement/penalties (â‚¬35M/7% turnover).


  Incorporate: Learning objectives [paste array]; Active learning for context (e.g., flashcards support classification/discussion);
  Scaffolding layers [paste scaffolding JSON] with just-in-time examples/diagrams described.


  Generate flashcards per ''flashcard_schema'' [paste schema]. Distribute: 20% Layer1, 30% Layer2, 30% Layer3, 20% Layer4.
  Span Bloom''s: 20% Remember/Understand, 30% Apply/Analyze, 30% Evaluate, 20% Create. Use research: broad AI def, risk-based,
  GPAI (e.g., LLMs), Providers/Deployers.


  Output ONLY valid JSON array of objects: [{''front'': ''Question'', ''back'': ''Answer'', ''explanation'': ''...'', ''blooms_level'':
  ''APPLY'', ''layer'': ''2'', ''tags'': [''High-Risk'', ''Providers'']}, ...]. No extras.'
