<?xml version="1.0" encoding="UTF-8"?>
<topic_prompt version="2.0">
  <metadata>
    <topic_title>Training Effectiveness Measurement</topic_title>
    <hierarchy>
      <category>Cybersecurity</category>
      <domain>Security And Risk Management</domain>
      <subdomain>Legal, Regulatory, and Compliance</subdomain>
      <entry_domain>Personnel Security and Ethics</entry_domain>
      <entry_subdomain>Security Awareness and Training Compliance</entry_subdomain>
    </hierarchy>
    <voting_summary>
      <consensus>True</consensus>
      <approval>100.0%</approval>
      <voters>7</voters>
    </voting_summary>
    <generation_timestamp>2026-01-01T11:03:43.377837</generation_timestamp>
  </metadata>
  <learning_objectives level="bloom_taxonomy">
    <objective level="remember" measurable="true" verbs="define">Define key terminology</objective>
    <objective level="understand" measurable="true" verbs="explain">Explain core concepts</objective>
    <objective level="apply" measurable="true" verbs="apply">Apply knowledge to scenarios</objective>
    <objective level="analyze" measurable="true" verbs="analyze">Analyze relationships</objective>
  </learning_objectives>
  <active_learning>
    <discussion_prompt>Evaluate the limitations of using only quantitative metrics (e.g., completion rates, test scores) for measuring cybersecurity training effectiveness. Propose a balanced set of quantitative and qualitative metrics based on NIST SP 800-50 Rev. 1, and debate their pros and cons in a group setting to encourage critical thinking about real-world applicability and misconceptions like over-relying on test scores.</discussion_prompt>
    <peer_teaching>Explain the key concepts to a partner without using technical jargon.</peer_teaching>
    <problem_solving>Given a scenario, apply the framework to solve the problem.</problem_solving>
  </active_learning>
  <scaffolding>
    <layer level="1" name="Foundation">
      <focus>Basic terminology and definitions</focus>
      <content/>
    </layer>
    <layer level="2" name="Components">
      <focus>Framework components and structure</focus>
      <content/>
    </layer>
    <layer level="3" name="Implementation">
      <focus>Practical implementation steps</focus>
      <content/>
    </layer>
    <layer level="4" name="Integration">
      <focus>Advanced integration and optimization</focus>
      <content/>
    </layer>
  </scaffolding>
  <flashcard_generation>
    <output_schema>
      <field name="question" type="string"/>
      <field name="correct_answer" type="string"/>
      <field name="distractors" type="[{'text': 'string', 'explanation': 'string'}]"/>
      <field name="explanation" type="string"/>
      <field name="bloom_level" type="enum"/>
      <field name="topic_hierarchy" type="object"/>
    </output_schema>
    <distractor_protocol>
      <step number="1">mcq_format</step>
      <step number="2">distractor_rules</step>
      <step number="3">quantity</step>
    </distractor_protocol>
    <system_prompt>You are an expert flashcard generator for cybersecurity education, specializing in Training Effectiveness Measurement (Topic Hierarchy: Cybersecurity &gt; Security And Risk Management &gt; Legal, Regulatory, and Compliance &gt; Personnel Security and Ethics &gt; Security Awareness and Training Compliance &gt; Training Effectiveness Measurement).
Generate 75 high-quality flashcards using the provided schema. Base content strictly on:
- Scaffolding layers (Layer 1 Foundation to Layer 4 Integration).
- Learning objectives across Bloom's Taxonomy.
- NIST SP 800-50 Rev. 1 (full CPLP life cycle: Plan/Develop, Implement, Evaluate, Improve; https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-50r1.pdf), Kirkpatrick model, CISSP domains.
- Key sources: NIST SP 800-50 Rev. 1; Kirkpatrick Four Levels (https://www.kirkpatrickpartners.com/The-New-World-of-Kirkpatrick-Four-Levels/); CISSP Official CBK.
Incorporate active learning: Include 10% of cards as discussion/peer-teach prompts (e.g., 'Debate: Why avoid only quant metrics?'). Ensure progressive scaffolding in card sequencing.
Output format: JSON array of objects, each: {'front': 'Question', 'back': {'answer': '...', 'explanation': '...', 'bloom_level': '...', 'layer': '1-4', 'references': '...'}}, MCQs with options array in front.
Balance: 20% Remember/Understand (Layer 1-2), 40% Apply/Analyze (Layer 2-3), 40% Evaluate/Create (Layer 3-4). Use distractor protocol for MCQs. Make explanations pedagogical, tying to real-world application and misconceptions.</system_prompt>
  </flashcard_generation>
</topic_prompt>