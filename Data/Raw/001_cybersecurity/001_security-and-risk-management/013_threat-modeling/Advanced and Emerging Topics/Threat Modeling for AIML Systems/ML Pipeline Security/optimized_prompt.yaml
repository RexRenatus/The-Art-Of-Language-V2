version: '2.0'
metadata:
  topic_title: ML Pipeline Security
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: Security And Risk Management
    level_3_subdomain: Threat Modeling
    level_4_entry_domain: Advanced and Emerging Topics
    level_5_entry_subdomain: Threat Modeling for AI/ML Systems
    level_6_topic: ML Pipeline Security
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 001_security-and-risk-management
    subdomain: 013_threat-modeling
  exa_sources: []
  voting:
    consensus_reached: true
    approval_percentage: 0.83
    total_voters: 7
  generation_timestamp: '2026-01-01T13:18:46.504548'
learning_objectives:
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
active_learning:
  discussion_prompt: Debate the trade-offs between model accuracy and security in ML pipelinesâ€”when should we prioritize one
    over the other, and why? Consider real-world implications in high-stakes fields like healthcare or autonomous systems.
  peer_teaching: Explain the key concepts to a partner without using technical jargon.
  problem_solving: Given a scenario, apply the framework to solve the problem.
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol: 'Generate 3 plausible distractors per MCQ: 1) Common misconception (e.g., ''Evasion attacks corrupt
    training data'' instead of inputs); 2) Similar term mix-up (e.g., STRIDE instead of ML-specific); 3) Partial truth (e.g.,
    correct stage but wrong attack type). Ensure distractors test deeper understanding per Bloom''s level.'
system_prompt: 'You are an expert flashcard generator for university-level cybersecurity education on ''ML Pipeline Security''
  (Topic Hierarchy: Cybersecurity > Security And Risk Management > Threat Modeling > Advanced and Emerging Topics > Threat
  Modeling for AI/ML Systems > ML Pipeline Security). Generate 30 high-quality flashcards (10 per Bloom''s pair: Remember/Understand,
  Apply/Analyze, Evaluate/Create) optimized for active recall, spaced repetition, and deep learning.


  Incorporate:

  - Learning Objectives: [PASTE FULL LIST FROM ABOVE]

  - Active Learning: Weave in discussion/peer teaching/problem-solving hooks in explanations.

  - Scaffolding: Distribute coverage: 8 Layer 1, 8 Layer 2, 8 Layer 3, 6 Layer 4. Cover core content: MLSecOps, ML Lifecycle
  (Design/Develop/Deploy/Operate/End-of-Life), AML attacks (evasion: adversarial inputs; poisoning: data corruption; prompt
  injection: direct/indirect), mitigations, DevSecOps links, NIST/NCSC/OpenSSF standards.

  - Big Picture: Emphasize criticality for secure AI in healthcare/autonomous systems.


  Use Flashcard Schema:

  [PASTE FULL SCHEMA FROM ABOVE]


  Output ONLY a JSON array of flashcards: [{''type'': ''...'', ''front'': ''...'', ''back'': {''answer'': ''...'', ''explanation'':
  ''...''}}, ...]. Ensure variety (1/3 definition, 1/3 MCQ, 1/3 scenario), measurable progress via Bloom''s, and formative
  reflection in explanations. No additional text.'
