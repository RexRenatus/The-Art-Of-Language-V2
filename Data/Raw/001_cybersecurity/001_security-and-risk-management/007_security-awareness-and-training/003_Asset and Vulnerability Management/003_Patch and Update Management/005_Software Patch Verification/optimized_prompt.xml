<?xml version="1.0" encoding="UTF-8"?>
<topic_prompt version="2.0">
  <metadata>
    <topic_title>Software Patch Verification</topic_title>
    <hierarchy>
      <category>Cybersecurity</category>
      <domain>Security And Risk Management</domain>
      <subdomain>Security Awareness and Training</subdomain>
      <entry_domain>Asset and Vulnerability Management</entry_domain>
      <entry_subdomain>Patch and Update Management</entry_subdomain>
    </hierarchy>
    <voting_summary>
      <consensus>True</consensus>
      <approval>100.0%</approval>
      <voters>7</voters>
    </voting_summary>
    <generation_timestamp>2026-01-01T11:38:41.184148</generation_timestamp>
  </metadata>
  <learning_objectives level="bloom_taxonomy">
    <objective level="remember" measurable="true" verbs="define">Define key terminology</objective>
    <objective level="understand" measurable="true" verbs="explain">Explain core concepts</objective>
    <objective level="apply" measurable="true" verbs="apply">Apply knowledge to scenarios</objective>
    <objective level="analyze" measurable="true" verbs="analyze">Analyze relationships</objective>
  </learning_objectives>
  <active_learning>
    <discussion_prompt>In a resource-constrained environment, should organizations prioritize functionality testing or integrity verification for patches? Debate using real-world examples like the SolarWinds supply chain attack, considering trade-offs in risk, compliance (e.g., NIST), and operational impact.</discussion_prompt>
    <peer_teaching>Explain the key concepts to a partner without using technical jargon.</peer_teaching>
    <problem_solving>Given a scenario, apply the framework to solve the problem.</problem_solving>
  </active_learning>
  <scaffolding>
    <layer level="1" name="Foundation">
      <focus>Basic terminology and definitions</focus>
      <content/>
    </layer>
    <layer level="2" name="Components">
      <focus>Framework components and structure</focus>
      <content/>
    </layer>
    <layer level="3" name="Implementation">
      <focus>Practical implementation steps</focus>
      <content/>
    </layer>
    <layer level="4" name="Integration">
      <focus>Advanced integration and optimization</focus>
      <content/>
    </layer>
  </scaffolding>
  <flashcard_generation>
    <output_schema>
      <field name="question" type="string"/>
      <field name="correct_answer" type="string"/>
      <field name="distractors" type="[{'text': 'string', 'explanation': 'string'}]"/>
      <field name="explanation" type="string"/>
      <field name="bloom_level" type="enum"/>
      <field name="topic_hierarchy" type="object"/>
    </output_schema>
    <distractor_protocol>
      <step number="1">rules</step>
    </distractor_protocol>
    <system_prompt>You are an expert flashcard generator for cybersecurity education, specializing in Software Patch Verification (Topic Hierarchy: Cybersecurity &gt; Security And Risk Management &gt; Security Awareness and Training &gt; Asset and Vulnerability Management &gt; Patch and Update Management &gt; Software Patch Verification).
Generate 25 high-quality flashcards using the exact schema provided. Cover all Bloom's levels via these objectives: [INSERT LEARNING_OBJECTIVES HERE]. Ensure scaffolding progression: Layer 1 Foundation (defs, prior knowledge), Layer 2 Components (techniques: hash/integrity, sandbox/functionality, compatibility), Layer 3 Implementation (steps/tools: Wireshark, VM), Layer 4 Integration (NIST SP 800-40 Rev. 4 on planning/preventive maintenance; SP 1800-31 on automation; big picture risk reduction).
Incorporate research: Patch verification validates integrity/functionality/compatibility to prevent malicious/faulty patches (e.g., SolarWinds). Sources: NIST SP 800-40 Rev. 4 (full guide: https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-40r4.pdf), NIST SP 1800-31 (https://www.nccoe.nist.gov/publication/1800-31/ApV).
Active learning tie-ins: Flashcards should support discussion (trade-offs), peer teaching (techniques), problem-solving (case studies).
Use FLASHCARD_SCHEMA exactly: Mix basic QA (40%), cloze (30%), MCQ (30%). For each: front/back/explanation. Distractors per protocol: misconceptions, partial truths, real-world errors.
Output as JSON array: [{'type': 'basic_qa|cloze|mcq', 'front': '...', 'back': '...', 'explanation': '...', 'bloom_level': 'REMEMBER|etc', 'scaffolding_layer': '1-4', 'distractors': ['d1','d2','d3'] (for MCQ only)}]. Ensure measurable, active recall, spaced repetition optimized (concise fronts, detailed backs).</system_prompt>
  </flashcard_generation>
</topic_prompt>