<?xml version="1.0" encoding="UTF-8"?>
<topic_prompt version="2.0">
  <metadata>
    <topic_title>Code Provenance Tracking</topic_title>
    <hierarchy>
      <category>Cybersecurity</category>
      <domain>008_Application Security</domain>
      <subdomain>Web 008_Application Security</subdomain>
      <entry_domain>015_Software 015_Supply Chain Security</entry_domain>
      <entry_subdomain>Code Integrity and Provenance</entry_subdomain>
    </hierarchy>
    <voting_summary>
      <consensus>True</consensus>
      <approval>100.0%</approval>
      <voters>7</voters>
    </voting_summary>
    <generation_timestamp>2026-01-18T12:08:49.794615</generation_timestamp>
  </metadata>
  <learning_objectives level="bloom_taxonomy">
    <objective level="remember" measurable="true" verbs="define">Define key terminology</objective>
    <objective level="understand" measurable="true" verbs="explain">Explain core concepts</objective>
    <objective level="apply" measurable="true" verbs="apply">Apply knowledge to scenarios</objective>
    <objective level="analyze" measurable="true" verbs="analyze">Analyze relationships</objective>
  </learning_objectives>
  <active_learning>
    <discussion_prompt>In a group discussion, debate the trade-offs of implementing full SLSA Level 4 provenance tracking in a resource-constrained web development team. Use SolarWinds and Log4j case studies to support arguments on failures due to poor provenance.</discussion_prompt>
    <peer_teaching>Explain the key concepts to a partner without using technical jargon.</peer_teaching>
    <problem_solving>Given a scenario, apply the framework to solve the problem.</problem_solving>
  </active_learning>
  <scaffolding>
    <layer level="1" name="Layer 1">
      <focus/>
      <content>Basic terms: Code provenance (verifiable history/origin of code), Software Supply Chain, SBOM (list of components/versions/origins), Attestation (signed verifiable claims). Concept Map: Central 'Code Provenance Tracking' → SBOM (components), Attestations (verification), Supply Chain (ecosystem). Checkpoint quiz: Define terms.</content>
    </layer>
    <layer level="2" name="Layer 2">
      <focus/>
      <content>Frameworks: SLSA (Levels 0-4 for artifact security; e.g., Level 1: tamper-evident source; https://slsa.dev/spec/v1.0/levels/), NIST SP 800-218 (SSDF practices like PO.8 for supplier review, PR.5 for build provenance). Tools: Sigstore (https://www.sigstore.dev/), in-toto (https://in-toto.io/). Concept Map extensions: SLSA → Levels hierarchy; NIST → PO/PR practices. Checkpoint: Match components to definitions.</content>
    </layer>
    <layer level="3" name="Layer 3">
      <focus/>
      <content>Practical steps: Generate SBOM (CycloneDX/SPDX), create attestations (SLSA Provenance predicate), verify artifacts. Examples: GitHub Actions for SLSA builds. Case studies intro: SolarWinds (build tampering hidden by no provenance), Log4j (unknown deps). Checkpoint: Simulate SBOM generation.</content>
    </layer>
    <layer level="4" name="Layer 4">
      <focus/>
      <content>Enterprise: Integrate with CI/CD, compliance (EO 14028). Full case studies: SolarWinds remediation via SBOM mandates; Log4j lessons for dynamic provenance. Advanced: Design systems with multi-track SLSA. Sources: SLSA (https://slsa.dev/), NIST SP 800-218 (https://csrc.nist.gov/pubs/sp/800/218/fpd), NTIA SBOM (https://www.ntia.gov/page/software-bill-materials). Final assessment: Evaluate/create scenario.</content>
    </layer>
  </scaffolding>
  <flashcard_generation>
    <output_schema>
      <field name="question" type="string"/>
      <field name="correct_answer" type="string"/>
      <field name="distractors" type="[{'text': 'string', 'explanation': 'string'}]"/>
      <field name="explanation" type="string"/>
      <field name="bloom_level" type="enum"/>
      <field name="topic_hierarchy" type="object"/>
    </output_schema>
    <distractor_protocol>
      <step number="1">Identify common misconceptions about the topic</step>
      <step number="2">Create plausible but incorrect alternatives</step>
      <step number="3">Ensure distractors are similar in length and complexity</step>
      <step number="4">Avoid obviously wrong answers</step>
      <step number="5">Include partial truths that require deeper understanding</step>
    </distractor_protocol>
    <system_prompt>You are an expert flashcard generator for cybersecurity education. Topic: Code Provenance Tracking (Hierarchy: Cybersecurity &gt; 008_Application Security &gt; Web 008_Application Security &gt; 015_Software 015_Supply Chain Security &gt; Code Integrity and Provenance &gt; Code Provenance Tracking). Use the provided learning objectives, active learning ideas, 4-layer scaffolding (with prior knowledge and concept map), and exact flashcard schema.
Prior Knowledge: Link to SBOM/supply chain basics. Content Sources: NIST SP 800-218 (https://doi.org/10.6028/NIST.SP.800-218), SLSA (https://slsa.dev/spec/v1.0/), Sigstore (https://www.sigstore.dev/), Cases: SolarWinds/Log4j.
Generate 30 flashcards covering all layers/objectives/Bloom's levels progressively (Layer 1 first). Ensure scaffolding: 7-8 cards/Layer 1 (Foundation), etc. Incorporate active elements (e.g., cards prompting 'Analyze like SolarWinds').
Output ONLY a JSON array of objects matching the EXACT flashcard schema. No extra text. Each card: high-quality, educational, with plausible 3 distractors (explain misconceptions). Balance: 40% recall, 30% application/analysis, 30% higher-order.</system_prompt>
  </flashcard_generation>
</topic_prompt>