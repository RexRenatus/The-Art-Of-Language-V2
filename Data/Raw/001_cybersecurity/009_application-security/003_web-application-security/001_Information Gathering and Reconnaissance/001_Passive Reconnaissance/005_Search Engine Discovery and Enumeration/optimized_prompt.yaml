version: '2.0'
metadata:
  topic_title: Search Engine Discovery and Enumeration
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: 008_Application Security
    level_3_subdomain: Web 008_Application Security
    level_4_entry_domain: 002_Information Gathering and Reconnaissance
    level_5_entry_subdomain: Passive Reconnaissance
    level_6_topic: Search Engine Discovery and Enumeration
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 009_application-security
    subdomain: 003_web-application-security
  exa_sources: []
  voting:
    consensus_reached: true
    approval_percentage: 0.83
    total_voters: 7
  generation_timestamp: '2026-01-18T12:01:59.918295'
learning_objectives:
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
active_learning:
  discussion_prompt: To what extent can passive reconnaissance via search engines reveal an organization's attack surface?
    Debate the balance between ethical information gathering and potential privacy violations, using OWASP WSTG examples like
    'Conduct Search Engine Discovery Reconnaissance for Information Leakage'. Address the misconception that 'passive' means
    harmless.
  peer_teaching: Explain the key concepts to a partner without using technical jargon.
  problem_solving: Given a scenario, apply the framework to solve the problem.
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol: 'Generate 3 plausible distractors per MCQ: 1) Common misconception (e.g., ''passive recon is always
    harmless''), 2) Confusable term (e.g., mix direct/indirect), 3) Partial truth (e.g., valid dork but wrong context). Ensure
    distractors are realistic from voter/research context (e.g., active scanning as non-example).'
system_prompt: 'You are an expert flashcard generator for cybersecurity education. Generate 25 high-quality Anki-style flashcards
  on ''Search Engine Discovery and Enumeration'' (Topic Hierarchy: Cybersecurity > 008_Application Security > Web 008_Application
  Security > 002_Information Gathering and Reconnaissance > Passive Reconnaissance > Search Engine Discovery and Enumeration).
  Integrate university pedagogy: Bloom''s Taxonomy objectives [insert learning_objectives array here], active learning [insert
  active_learning object here], 4-layer scaffolding [insert scaffolding_layers object here].


  Use exact flashcard_schema: Front (question), Back (answer, bloom_level, scaffolding_layer, explanation with OWASP WSTG/NIST/Google
  dorks examples, active_learning_link, sources). Follow distractor_protocol strictly for MCQs.


  Key content from research: Crawling/indexing, direct/indirect methods, info leakage, OWASP WSTG ''Conduct Search Engine
  Discovery Reconnaissance''. Voter priorities: Google dorks examples, ethical debates, peer activities, concept map.


  Output as JSON array of flashcards: [{''front'': ''...'', ''back'': {''answer'': ''...'', ''bloom_level'': ''...'', ...}}].
  Ensure spaced repetition optimization: varied formats (MCQ 50%, cloze 30%, Q&A 20%). No duplicates; cover all objectives/layers.'
