version: '2.0'
metadata:
  topic_title: Runtime Instrumentation Detection
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: 008_Application Security
    level_3_subdomain: Mobile 008_Application Security
    level_4_entry_domain: 009_Resilience Against Reverse Engineering
    level_5_entry_subdomain: 006_Runtime Application Self-Protection (RASP)
    level_6_topic: Runtime Instrumentation Detection
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 009_application-security
    subdomain: 004_mobile-application-security
  exa_sources: []
  voting:
    consensus_reached: true
    approval_percentage: 0.83
    total_voters: 7
  generation_timestamp: '2026-01-18T12:29:24.508664'
learning_objectives:
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
active_learning:
  discussion_prompt: 'In a group discussion, debate the trade-offs between DBI transparency and security in mobile apps: How
    does detecting instrumentation enhance RASP resilience against MITRE ATT&CK tactics like T1027 (Obfuscated Files or Information)
    and T1622 (Debugger Evasion), and what risks does it introduce for legitimate analysis tools? Support with examples from
    malware evasion.'
  peer_teaching: Explain the key concepts to a partner without using technical jargon.
  problem_solving: Given a scenario, apply the framework to solve the problem.
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol: 'Create 3-4 plausible distractors per MCQ: (1) Common misconceptions (e.g., confuse DBI with static
    instrumentation); (2) Related but incorrect terms (e.g., ''static analysis'' instead of ''dynamic''); (3) Partial truths
    (e.g., valid for debuggers but not DBI); (4) Edge cases from mobile contexts (e.g., emulator noise vs. true jitter). Ensure
    distractors test deeper understanding and align with voter consensus on artifacts/evasion.'
system_prompt: 'You are an expert flashcard generator for cybersecurity education, specializing in ''Runtime Instrumentation
  Detection'' (Topic Hierarchy: Cybersecurity > 008_Application Security > Mobile 008_Application Security > 009_Resilience
  Against Reverse Engineering > 006_Runtime Application Self-Protection (RASP) > Runtime Instrumentation Detection). Voter
  consensus: 82.9% approval emphasizes Bloom''s Taxonomy progression, 4-layer scaffolding, hands-on activities, prior knowledge
  links, and complete MITRE ATT&CK coverage (T1027: Obfuscated Files/Info for evasion; T1622: Debugger/Instrumentation Detection).


  Core Content (Research Context): DBI inserts probes into running programs (engines: PIN, DynamoRIO, Frida); introduces artifacts
  (timing jitter, syscall hooks, code caches); detection via timing/memory/trace analysis. Big picture: Enhances mobile RASP
  against cracking/malware (sources: diag.uniroma1.it, season-lab.github.io).


  Use these exact elements:

  - Learning Objectives: [insert full list above]

  - Active Learning: [insert summaries]

  - Scaffolding: [insert 4 layers]


  Generate flashcards following the Flashcard Schema exactly. Distribute: 30% Layer1/REMEMBER-UNDERSTAND, 30% Layer2-3/APPLY-ANALYZE,
  40% Layer4/EVALUATE-CREATE. Mix MCQ (70%) and Short Answer (30%). Output as a JSON array of flashcard objects. Ensure university
  pedagogy: active recall, spaced repetition, distractors for critical thinking.'
