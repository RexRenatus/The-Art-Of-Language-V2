version: '2.0'
metadata:
  topic_title: Manual code review processes
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: 008_Application Security
    level_3_subdomain: Secure Software Development Lifecycle
    level_4_entry_domain: 008_Security Testing and Verification
    level_5_entry_subdomain: Static Analysis and Code Review
    level_6_topic: Manual code review processes
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 009_application-security
    subdomain: 001_secure-software-development-lifecycle
  exa_sources: []
  voting:
    consensus_reached: true
    approval_percentage: 0.83
    total_voters: 7
  generation_timestamp: '2026-01-18T11:49:04.388567'
learning_objectives:
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
active_learning:
  discussion_prompt: In what scenarios do manual code reviews outperform automated static analysis tools, and vice versa?
    Use examples from OWASP Top 10 (e.g., broken access control or injection flaws) to debate, considering factors like false
    positives, subtle business logic flaws, and developer context. Discuss misconceptions that manual reviews are obsolete
    in modern CI/CD pipelines.
  peer_teaching: Explain the key concepts to a partner without using technical jargon.
  problem_solving: Given a scenario, apply the framework to solve the problem.
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol: 'For MCQ (50% of cards): Generate 4 options (A-D), 1 correct. Distractors: Plausible based on common
    misconceptions (e.g., ''Manual reviews replace SAST'' vs. ''complement''); real but incorrect standards (e.g., NIST SP
    800-53 instead of 800-218); partial truths (e.g., ignore business logic flaws). Ensure balanced difficulty.'
system_prompt: 'You are an expert flashcard generator for cybersecurity education, specializing in Application Security (Domain:
  008_Application Security > Secure Software Development Lifecycle > 008_Security Testing and Verification > Static Analysis
  and Code Review > Manual code review processes). Topic Hierarchy: Cybersecurity > Level1-6 as specified.


  Generate 25-35 high-quality, spaced-repetition optimized flashcards using the EXACT schema provided below. Base content
  STRICTLY on this structured knowledge, voter consensus (82.9% approval), and web research (OWASP Code Review Guide, NIST
  SP 800-218 for secure SDLC, CWE, SAMM; manual review catches human-context flaws automated tools miss).


  **Pedagogical Integration:**

  - Align to these Learning Objectives [insert full list above].

  - Scaffold across 4 Layers + Prior Knowledge [insert full scaffolding above].

  - Infuse active learning: Reference discussion (manual vs. automated scenarios), peer teaching (code snippet reviews), problem-solving
  (OWASP vuln fixes).

  - University pedagogy: Bloom''s progression, active recall, metacognition via explanations.


  **Knowledge Synthesis:**

  - Foundation: Definitions, SDLC role.

  - Components: Roles/checklists/tools.

  - Implementation: Steps (prep, Fagan/pairing, report).

  - Integration: SAST hybrid, metrics, standards (complete NIST: SP 800-218 integrates security in verification; OWASP Guide
  emphasizes manual for Top 10).

  - Examples: Insecure code snippets (e.g., unvalidated input leading to XSS).


  **Output ONLY the JSON array of flashcards per the Flashcard Schema [insert full schema above]. No intro text. Ensure variety,
  no duplicates, educationally rigorous (plausible distractors, source citations).'
