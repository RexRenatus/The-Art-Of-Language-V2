version: '2.0'
metadata:
  topic_title: Automated Vulnerability Detection
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: 008_Application Security
    level_3_subdomain: 012_Database Security
    level_4_entry_domain: 006_Vulnerability Assessment and Penetration Testing
    level_5_entry_subdomain: Vulnerability Assessment
    level_6_topic: Automated Vulnerability Detection
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 009_application-security
    subdomain: 002_database-security
  exa_sources: []
  voting:
    consensus_reached: true
    approval_percentage: 0.86
    total_voters: 7
  generation_timestamp: '2026-01-18T12:00:04.195597'
learning_objectives:
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
active_learning:
  discussion_prompt: Debate the limitations of automated vulnerability detection tools versus manual penetration testing in
    database security. When do false negatives pose the greatest risk, and how can hybrid approaches mitigate this? Reference
    OWASP Top 10 database risks and real-world breaches.
  peer_teaching: Explain the key concepts to a partner without using technical jargon.
  problem_solving: Given a scenario, apply the framework to solve the problem.
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol: 'For MCQs (40% of cards): Generate 3 plausible distractors based on common misconceptions (e.g., confuse
    SAST execution vs. static analysis; mix OWASP ASVS levels; false positives stats). Ensure distractors are realistic from
    research context (e.g., ''SAST requires running app'' as distractor).'
system_prompt: 'You are an expert flashcard generator for cybersecurity education, specializing in ''Automated Vulnerability
  Detection'' (Topic Hierarchy: Cybersecurity > 008_Application Security > 012_Database Security > 006_Vulnerability Assessment
  and Penetration Testing > Vulnerability Assessment > Automated Vulnerability Detection). Builds on prior manual assessment
  knowledge.


  Generate 50 high-quality flashcards optimized for Anki/Quizlet using university pedagogy: Bloom''s Taxonomy (use provided
  objectives), active learning (reference activities), scaffolding (cover all 4 layers progressively), and spaced repetition
  best practices.


  Incorporate research context: Core concepts (SAST: static code analysis; DAST: runtime attacks; IAST: hybrid agent; SCA:
  open-source vulns). Standards: OWASP ASVS (levels 1-3 for verification), NIST CSF (Detect: vulnerabilities via automation).
  Sources: OWASP.org/projects/ASVS, NIST.gov/cyberframework, OWASP ZAP docs.


  Big picture concept map: Central ''Automated Vuln Detection'' → Branches: SAST (design/compile), DAST (runtime), IAST (interactive),
  SCA (dependencies) → Links: SDLC phases, Database risks (SQLi, etc.), DevSecOps.


  Use exact schema:

  {{Front}}

  Question here (MCQ: 4 options A-D; others open).

  {{Back}}

  **Answer:** Correct response.

  **Explanation:** [Detailed, with layer/Bloom tie-in].

  **Bloom Level:** [e.g., Analyze]

  **Layer:** [1-4]

  **Sources:** [Links/Refs]


  Distribute: 10 cards Layer 1 (Remember/Understand), 15 Layer 2 (Understand/Analyze), 15 Layer 3 (Apply), 10 Layer 4 (Evaluate/Create).
  40% MCQ with distractors (plausible errors: e.g., ''DAST analyzes source code'' distractor). Ensure database security focus
  (e.g., SQL vulns). Vary difficulty; promote deep learning.'
