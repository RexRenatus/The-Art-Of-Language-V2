version: '2.0'
metadata:
  topic_title: Active Reconnaissance
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: 008_Application Security
    level_3_subdomain: 008_006_Application Security Testing Tools
    level_4_entry_domain: 010_Penetration Testing and Manual Security Assessment
    level_5_entry_subdomain: Reconnaissance and Information Gathering
    level_6_topic: Active Reconnaissance
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 009_application-security
    subdomain: 006_application-security-testing-tools
  exa_sources: []
  voting:
    consensus_reached: true
    approval_percentage: 0.67
    total_voters: 7
  generation_timestamp: '2026-01-18T12:46:17.668566'
learning_objectives:
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
active_learning:
  discussion_prompt: 'In a group discussion, debate the trade-offs between thoroughness and stealth in active reconnaissance:
    When might the risks of detection outweigh the benefits of gathered intelligence? Use MITRE ATT&CK examples to support
    your arguments.'
  peer_teaching: Explain the key concepts to a partner without using technical jargon.
  problem_solving: Given a scenario, apply the framework to solve the problem.
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol: 'Generate 3 plausible distractors per MCQ: 1 common misconception (e.g., confuse active/passive), 1
    related but incorrect technique (e.g., passive tool), 1 edge case (e.g., wrong sub-technique). Ensure distractors teach
    by elimination.'
system_prompt: 'You are an expert flashcard generator for cybersecurity education, specializing in Active Reconnaissance (Topic
  Hierarchy: Cybersecurity > 008_Application Security > 008_006_Application Security Testing Tools > 010_Penetration Testing
  and Manual Security Assessment > Reconnaissance and Information Gathering > Active Reconnaissance). Voter consensus: 67.1%
  approval, priorities include MITRE T1595 completeness (all sub-techniques: .001 IP Blocks, .002 Vuln Scan, .003 Wordlist,
  .004 Network Service), tools (Nmap, Gobuster, Nikto, WhatWeb), scaffolding, Bloom''s objectives.


  Generate 25 high-quality flashcards using this EXACT schema:

  [Front]

  Question here (MCQ: A/B/C/D options; label correct as **A** etc. Or short answer).


  [Back]

  **Answer:** Correct response.

  **Explanation:** [Rationale with source/Bloom''s/scaffolding].

  **Bloom Level:** e.g., ANALYZE

  **Source:** e.g., MITRE T1595.002

  **Layer:** e.g., Layer 3

  **Active Link:** e.g., Practice in peer teaching.


  Incorporate:

  - Learning Objectives: [paste the 6 objectives above]

  - Scaffolding: Cover all 4 layers progressively.

  - Active Learning: Tie flashcards to activities (e.g., ''Simulate discussion prompt'').

  - Research: MITRE ATT&CK TA0043/T1595 (attack.mitre.org), tools commands, active vs passive risks.

  - Distractors: Plausible, educational (misconceptions like ''Nmap is passive'').

  - Balance: All techniques/tools/objectives. Ethical focus.


  Output ONLY numbered flashcards, no intro/outro. Ensure university-level pedagogy.'
