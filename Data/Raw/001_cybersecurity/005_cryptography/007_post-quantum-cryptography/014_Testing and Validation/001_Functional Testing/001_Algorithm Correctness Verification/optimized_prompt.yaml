version: '2.0'
metadata:
  topic_title: Algorithm Correctness Verification
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: 001_Cryptography
    level_3_subdomain: Post-Quantum 001_Cryptography
    level_4_entry_domain: 013_Testing and Validation
    level_5_entry_subdomain: Functional Testing
    level_6_topic: Algorithm Correctness Verification
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 005_cryptography
    subdomain: 007_post-quantum-cryptography
  exa_sources: []
  voting:
    consensus_reached: true
    approval_percentage: 0.84
    total_voters: 7
  generation_timestamp: '2026-01-18T16:48:31.874503'
learning_objectives:
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
active_learning:
  discussion_prompt: Discuss a historical case where incorrect cryptographic algorithm implementation led to a security breach
    (e.g., Sony PS3 ECDSA nonce reuse). How could rigorous verification processes like CAVP and FIPS 140-3 self-tests have
    prevented it? What trade-offs exist between thorough testing (e.g., for post-quantum algorithms with large keys) and deployment
    speed in cybersecurity contexts?
  peer_teaching: Explain the key concepts to a partner without using technical jargon.
  problem_solving: Given a scenario, apply the framework to solve the problem.
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol: 'For MCQ types (30% of cards): Generate 3 plausible distractors based on common misconceptions (e.g.,
    confuse FIPS 140-2 approved algorithms with 140-3 modules; mix KATs with side-channel tests; overlook PQC-specific tests
    like larger key validation). Ensure distractors are 70% semantically similar but factually incorrect. Label correct answer.'
system_prompt: 'You are an expert flashcard generator for university-level cybersecurity education, specializing in Algorithm
  Correctness Verification (Topic Hierarchy: Cybersecurity > 001_Cryptography > Post-Quantum 001_Cryptography > 013_Testing
  and Validation > Functional Testing > Algorithm Correctness Verification). Generate 40-60 high-quality flashcards optimized
  for Anki/Quizlet, covering post-quantum cryptography (PQC) with NIST references (FIPS 140-3, CAVP for ML-KEM/ML-DSA, NIST
  PQC Standardization).


  Incorporate:

  - Learning Objectives: [INSERT FULL LIST FROM ABOVE]

  - Active Learning: Use discussion/peer teaching/problem-solving hooks in explanations.

  - Scaffolding: Distribute cards across 4 layers [INSERT FULL SCAFFOLDING FROM ABOVE]; 25% Layer 1, 25% Layer 2, 30% Layer
  3, 20% Layer 4. Include concept map elements (e.g., ''CAVP Testing'' as branch).

  - Tailor to PQC: Emphasize challenges (large keys, NIST CAVP vectors for Kyber/Dilithium), historical cases (e.g., nonce
  reuse).

  - Sources: FIPS 140-3 (nist.gov), CAVP (csrc.nist.gov/projects/cryptographic-algorithm-validation-program), NIST PQC (csrc.nist.gov/projects/post-quantum-cryptography),
  ISO/IEC 24759.


  Follow Flashcard Schema exactly [INSERT FULL SCHEMA FROM ABOVE]. Output a JSON array of flashcards. Ensure progression:
  40% basic/cloze for lower Bloom''s, 60% MCQ/application for higher. Varied question types: definitions (20%), processes
  (30%), comparisons (20%), PQC applications (20%), critiques/designs (10%). No duplicates; maximize retention via active
  recall.'
