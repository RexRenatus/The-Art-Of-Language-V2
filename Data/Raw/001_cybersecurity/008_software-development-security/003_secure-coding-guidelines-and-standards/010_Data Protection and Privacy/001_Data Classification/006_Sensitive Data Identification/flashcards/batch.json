{
  "topic_title": "Sensitive Data Identification",
  "category": "Software Development Security - Secure Coding Guidelines and Standards",
  "flashcards": [
    {
      "question_text": "According to NIST SP 800-63-4, what is the primary goal of identity proofing in digital identity management?",
      "correct_answer": "To establish a sufficient level of confidence that a subject is who they claim to be.",
      "distractors": [
        {
          "text": "To verify that a user has access to a specific system.",
          "misconception": "Targets [scope confusion]: Confuses identity proofing with access control or authentication."
        },
        {
          "text": "To ensure the confidentiality of user credentials.",
          "misconception": "Targets [purpose confusion]: Mixes identity proofing with credential security, which is a related but distinct process."
        },
        {
          "text": "To determine the user's role and permissions within an organization.",
          "misconception": "Targets [process confusion]: Equates identity proofing with authorization, which occurs after identity is established."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Identity proofing establishes confidence in a user's claimed identity before authentication. It works by collecting and verifying identity attributes, ensuring the foundation for secure access and preventing impersonation.",
        "distractor_analysis": "The distractors incorrectly focus on access control, credential security, or authorization, which are subsequent steps or related but different processes in digital identity management.",
        "analogy": "Identity proofing is like a bouncer checking your ID at a club entrance to confirm you are who your ticket says you are, before you can enter and engage in activities inside."
      },
      "code_snippets": [],
      "difficulty": "foundational",
      "question_type": "definition",
      "bloom_level": "understand",
      "prerequisites": [
        "DIGITAL_IDENTITY_BASICS",
        "NIST_SP_800_63_4"
      ]
    },
    {
      "question_text": "Which NIST publication provides comprehensive guidelines for digital identity, including identity proofing, authentication, and federation?",
      "correct_answer": "NIST Special Publication (SP) 800-63-4, Digital Identity Guidelines",
      "distractors": [
        {
          "text": "NIST Special Publication (SP) 800-53 Revision 5, Security and Privacy Controls for Information Systems and Organizations",
          "misconception": "Targets [scope confusion]: SP 800-53 covers broader security controls, not specifically focused on digital identity lifecycle management."
        },
        {
          "text": "NIST Internal Report (IR) 8496 ipd, Data Classification Concepts and Considerations for Improving Data Protection",
          "misconception": "Targets [domain confusion]: This IR focuses on data classification, which is related to sensitive data but not the primary source for digital identity guidelines."
        },
        {
          "text": "NIST Special Publication (SP) 1800-28, Data Confidentiality: Identifying and Protecting Assets Against Data Breaches",
          "misconception": "Targets [granularity error]: This SP focuses on data confidentiality and breach protection, not the foundational aspects of digital identity management."
        }
      ],
      "detailed_explanation": {
        "core_logic": "NIST SP 800-63-4 is the definitive guide for digital identity, detailing requirements for identity proofing, authentication, and federation. It supersedes SP 800-63-3, providing updated technical requirements.",
        "distractor_analysis": "The distractors represent other NIST publications that cover related but distinct areas like general security controls, data classification, or data confidentiality, not the specific lifecycle of digital identity.",
        "analogy": "If digital identity is a person's passport, SP 800-63-4 is the comprehensive rulebook for how that passport is issued, verified, and used for travel."
      },
      "code_snippets": [],
      "difficulty": "foundational",
      "question_type": "definition",
      "bloom_level": "remember",
      "prerequisites": [
        "NIST_CYBERSECURITY_FRAMEWORK",
        "DIGITAL_IDENTITY_BASICS"
      ]
    },
    {
      "question_text": "In the context of software development security, what is the primary objective of data classification?",
      "correct_answer": "To categorize data based on its sensitivity and criticality to determine appropriate protection measures.",
      "distractors": [
        {
          "text": "To ensure all data is encrypted at rest and in transit.",
          "misconception": "Targets [over-application]: Assumes a single protection mechanism for all data, ignoring varying sensitivity levels."
        },
        {
          "text": "To identify all personally identifiable information (PII) within a system.",
          "misconception": "Targets [scope limitation]: PII is a type of sensitive data, but classification encompasses more than just PII."
        },
        {
          "text": "To create a comprehensive inventory of all data assets.",
          "misconception": "Targets [process confusion]: Data inventory is a precursor or component, but classification is about assigning value and protection levels."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Data classification is crucial because it enables organizations to apply appropriate security controls based on data sensitivity. It works by establishing a framework to categorize data, thereby guiding decisions on protection, access, and retention.",
        "distractor_analysis": "The distractors focus on specific security controls, a subset of sensitive data (PII), or data inventory, rather than the overarching purpose of assigning protection levels based on sensitivity.",
        "analogy": "Data classification is like sorting mail: junk mail gets discarded, personal letters are handled with care, and important legal documents are stored securely in a safe."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "definition",
      "bloom_level": "understand",
      "prerequisites": [
        "DATA_PROTECTION_PRINCIPLES",
        "SDLC_SECURITY"
      ]
    },
    {
      "question_text": "Which of the following is a key consideration when identifying sensitive data in software development, as highlighted by NIST IR 8496?",
      "correct_answer": "Understanding the potential impact of unauthorized disclosure or modification on the organization and individuals.",
      "distractors": [
        {
          "text": "Focusing solely on data that is publicly accessible.",
          "misconception": "Targets [scope limitation]: Sensitive data is by definition not intended for public access; this focuses on the opposite."
        },
        {
          "text": "Prioritizing data based on its storage location (e.g., cloud vs. on-premises).",
          "misconception": "Targets [misplaced priority]: While location is a factor in protection, sensitivity is determined by content and impact, not just storage."
        },
        {
          "text": "Identifying data that is frequently updated or modified.",
          "misconception": "Targets [irrelevant factor]: The frequency of modification does not inherently determine data sensitivity."
        }
      ],
      "detailed_explanation": {
        "core_logic": "NIST IR 8496 emphasizes that identifying sensitive data requires understanding the potential impact of breaches. This understanding guides the selection of appropriate security controls, because the goal is to protect against harm.",
        "distractor_analysis": "The distractors suggest focusing on public data, storage location, or modification frequency, which are not the primary drivers for identifying and classifying sensitive data according to NIST's guidance on data protection.",
        "analogy": "When identifying valuables to protect in your home, you prioritize items with high monetary or sentimental value (impact), not just items that are easy to reach or frequently moved."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "DATA_CLASSIFICATION",
        "NIST_IR_8496"
      ]
    },
    {
      "question_text": "What is the primary purpose of data confidentiality controls in software development, as discussed in NIST SP 1800-28?",
      "correct_answer": "To prevent unauthorized access, disclosure, or exfiltration of sensitive information.",
      "distractors": [
        {
          "text": "To ensure the availability of data for authorized users.",
          "misconception": "Targets [purpose confusion]: This describes data availability, a different CIA triad principle than confidentiality."
        },
        {
          "text": "To guarantee the integrity and accuracy of data.",
          "misconception": "Targets [purpose confusion]: This describes data integrity, another distinct principle from confidentiality."
        },
        {
          "text": "To facilitate rapid data recovery after a system failure.",
          "misconception": "Targets [scope limitation]: This relates to disaster recovery and business continuity, not the direct protection of data from unauthorized eyes."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Data confidentiality controls work by implementing measures that restrict access to sensitive data, thereby preventing unauthorized disclosure. This is essential because breaches can lead to significant operational, financial, and reputational damage.",
        "distractor_analysis": "The distractors incorrectly describe data availability, integrity, or recovery, which are separate security objectives from confidentiality, though often addressed by comprehensive security strategies.",
        "analogy": "Data confidentiality is like keeping your personal diary locked away; it ensures that only you (or those you explicitly permit) can read its contents."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "definition",
      "bloom_level": "understand",
      "prerequisites": [
        "DATA_CONFIDENTIALITY",
        "NIST_SP_1800_28"
      ]
    },
    {
      "question_text": "When developing software, what is the significance of identifying and protecting Personally Identifiable Information (PII)?",
      "correct_answer": "PII is a category of sensitive data that, if compromised, can lead to identity theft, financial loss, and reputational damage for individuals and organizations.",
      "distractors": [
        {
          "text": "PII is only relevant for compliance with GDPR and CCPA regulations.",
          "misconception": "Targets [regulatory scope limitation]: While regulations mandate protection, the harm from PII compromise extends beyond specific laws."
        },
        {
          "text": "PII is inherently less sensitive than financial data and requires minimal protection.",
          "misconception": "Targets [sensitivity misjudgment]: PII can be as, or more, sensitive than financial data depending on context and potential for misuse."
        },
        {
          "text": "PII only needs to be protected when stored in databases, not during transmission.",
          "misconception": "Targets [transmission security oversight]: PII is sensitive during both storage (at rest) and transmission (in transit)."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Protecting PII is critical because its compromise can directly harm individuals and organizations. Software must be designed to handle PII securely, because unauthorized access can lead to identity theft and significant legal/financial repercussions.",
        "distractor_analysis": "The distractors incorrectly limit PII's relevance to specific regulations, downplay its sensitivity, or ignore the need for protection during data transmission.",
        "analogy": "PII is like a person's social security number and home address; losing it can lead to serious personal and financial trouble for that individual."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "PII_DEFINITION",
        "DATA_PRIVACY_LAWS"
      ]
    },
    {
      "question_text": "What is the role of data masking in protecting sensitive data during software development and testing?",
      "correct_answer": "To replace sensitive data with realistic but fictitious data, preserving data utility while reducing risk.",
      "distractors": [
        {
          "text": "To permanently delete sensitive data from non-production environments.",
          "misconception": "Targets [destructive approach]: Masking is about transformation, not deletion, which would render data unusable for testing."
        },
        {
          "text": "To encrypt all sensitive data before it is used in testing.",
          "misconception": "Targets [method confusion]: Encryption is a protection method, but masking specifically aims to create substitute data for utility."
        },
        {
          "text": "To restrict access to sensitive data only to senior developers.",
          "misconception": "Targets [access control confusion]: Masking is a data transformation technique, not an access control mechanism."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Data masking works by substituting sensitive data with altered, non-sensitive equivalents, thereby maintaining data format and usability for testing. This is crucial because using real sensitive data in non-production environments poses significant risks.",
        "distractor_analysis": "The distractors suggest deletion, encryption, or access restriction, which are different security measures or inappropriate actions for maintaining data utility in testing environments.",
        "analogy": "Data masking is like using a stand-in actor for a stunt scene in a movie; the action is performed realistically, but the star actor (sensitive data) is not put at risk."
      },
      "code_snippets": [],
      "difficulty": "advanced",
      "question_type": "definition",
      "bloom_level": "understand",
      "prerequisites": [
        "DATA_MASKING",
        "SECURE_TESTING"
      ]
    },
    {
      "question_text": "Consider a scenario where a web application handles user payment information. Which of the following represents the MOST sensitive type of data that needs stringent identification and protection?",
      "correct_answer": "Full credit card numbers (Primary Account Number - PAN) and CVV codes.",
      "distractors": [
        {
          "text": "Usernames and email addresses.",
          "misconception": "Targets [sensitivity misjudgment]: While PII, these are generally less sensitive than financial card data."
        },
        {
          "text": "Billing addresses.",
          "misconception": "Targets [sensitivity misjudgment]: Billing addresses are sensitive PII but typically less critical than direct payment credentials."
        },
        {
          "text": "Order history.",
          "misconception": "Targets [scope limitation]: Order history can be sensitive when linked to PII, but the payment details themselves are the highest risk."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Full credit card numbers (PAN) and CVV codes are highly sensitive because they can be directly used for fraudulent transactions. Protecting them is paramount, because their compromise leads to immediate financial loss and severe compliance violations (e.g., PCI-DSS).",
        "distractor_analysis": "Usernames, email addresses, and billing addresses are sensitive PII but do not grant direct financial access. Order history is sensitive in context but less critical than the raw payment credentials.",
        "analogy": "In a bank, the vault containing cash (credit card numbers/CVV) is the most heavily guarded area, far more so than the customer service desk (email/username) or the lobby (order history)."
      },
      "code_snippets": [],
      "difficulty": "advanced",
      "question_type": "scenario",
      "bloom_level": "apply",
      "prerequisites": [
        "PCI_DSS",
        "PAYMENT_CARD_SECURITY"
      ]
    },
    {
      "question_text": "What is the primary risk associated with failing to properly identify and classify sensitive data in software development?",
      "correct_answer": "Inadequate security controls leading to data breaches, regulatory fines, reputational damage, and loss of customer trust.",
      "distractors": [
        {
          "text": "Increased development time and complexity.",
          "misconception": "Targets [misplaced priority]: While security adds complexity, the primary risk is not development overhead but security failure."
        },
        {
          "text": "Underutilization of data analytics capabilities.",
          "misconception": "Targets [irrelevant consequence]: Failure to classify data impacts security, not typically data analytics potential."
        },
        {
          "text": "Over-reliance on third-party security solutions.",
          "misconception": "Targets [symptom vs. cause]: Over-reliance might be a consequence of poor internal processes, but the root risk is the data breach itself."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Failing to identify and classify sensitive data means security controls will be misapplied or insufficient, directly increasing the risk of breaches. This happens because without knowing what's sensitive, you can't protect it effectively, leading to severe consequences.",
        "distractor_analysis": "The distractors focus on development efficiency, data analytics, or reliance on external tools, rather than the core security risks of data breaches and their associated fallout.",
        "analogy": "Not identifying sensitive data is like not knowing which items in your house are valuable antiques; you might leave them unprotected near an open window, risking theft and loss."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "DATA_BREACH_IMPACTS",
        "RISK_MANAGEMENT"
      ]
    },
    {
      "question_text": "Which of the following best describes the concept of 'data minimization' in the context of sensitive data handling during software development?",
      "correct_answer": "Collecting and retaining only the minimum amount of sensitive data necessary for a specific, legitimate purpose.",
      "distractors": [
        {
          "text": "Encrypting all collected sensitive data to ensure its protection.",
          "misconception": "Targets [method vs. principle]: Encryption is a protection method, while minimization is about reducing the data collected in the first place."
        },
        {
          "text": "Aggregating all sensitive data into a single, highly secured repository.",
          "misconception": "Targets [centralization risk]: While consolidation can aid security, the principle is to collect less, not necessarily centralize more."
        },
        {
          "text": "Anonymizing sensitive data after it has been collected and used.",
          "misconception": "Targets [timing error]: Minimization is about *prevention* of collection, not post-collection anonymization, though anonymization is a related privacy technique."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Data minimization is a core privacy principle that reduces risk by limiting the attack surface. It works by preventing the collection or retention of unnecessary sensitive data, because the less data you have, the less there is to lose or misuse.",
        "distractor_analysis": "The distractors describe encryption, data aggregation, or anonymization, which are related but distinct privacy/security practices, not the principle of collecting less data.",
        "analogy": "Data minimization is like only bringing essential items on a camping trip; you don't pack your entire house, just what you need for the duration, reducing what you have to carry and protect."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "definition",
      "bloom_level": "understand",
      "prerequisites": [
        "DATA_MINIMIZATION",
        "PRIVACY_BY_DESIGN"
      ]
    },
    {
      "question_text": "What is the primary challenge in identifying sensitive data within unstructured text (e.g., logs, user comments)?",
      "correct_answer": "The lack of predefined fields and formats makes automated detection difficult, requiring sophisticated Natural Language Processing (NLP) techniques.",
      "distractors": [
        {
          "text": "Unstructured data is inherently less sensitive than structured data.",
          "misconception": "Targets [sensitivity misjudgment]: Unstructured data can contain highly sensitive information (e.g., PII in a log message)."
        },
        {
          "text": "Sensitive data in unstructured text is always explicitly labeled.",
          "misconception": "Targets [assumption error]: Sensitive data in free-form text is often embedded without clear labels."
        },
        {
          "text": "Only structured databases require sensitive data identification efforts.",
          "misconception": "Targets [scope limitation]: Sensitive data can exist in any data format, including unstructured text files, emails, etc."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Identifying sensitive data in unstructured text is challenging because it lacks the predictable schema of structured data. NLP techniques are needed to infer context and identify patterns, because simple pattern matching is often insufficient.",
        "distractor_analysis": "The distractors incorrectly assume unstructured data is less sensitive, always labeled, or that only structured data needs scrutiny, ignoring the reality of sensitive information embedded in free-form text.",
        "analogy": "Finding a specific needle (sensitive data) in a haystack (unstructured text) is harder than finding a specific coin (structured data) in a coin jar; the haystack lacks organization."
      },
      "code_snippets": [],
      "difficulty": "advanced",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "DATA_TYPES",
        "NLP_BASICS"
      ]
    },
    {
      "question_text": "Which of the following is a common technique for detecting sensitive data in code repositories?",
      "correct_answer": "Using static analysis security testing (SAST) tools that scan for hardcoded secrets like API keys and passwords.",
      "distractors": [
        {
          "text": "Manually reviewing every line of code for potential vulnerabilities.",
          "misconception": "Targets [scalability issue]: Manual review is impractical for large codebases and prone to human error."
        },
        {
          "text": "Monitoring network traffic for data exfiltration attempts.",
          "misconception": "Targets [detection timing error]: Network monitoring detects breaches in progress or after the fact, not sensitive data embedded in code."
        },
        {
          "text": "Performing dynamic analysis security testing (DAST) on deployed applications.",
          "misconception": "Targets [analysis type confusion]: DAST tests running applications, not static code for embedded secrets."
        }
      ],
      "detailed_explanation": {
        "core_logic": "SAST tools are designed to analyze source code without executing it, effectively finding hardcoded secrets. This is crucial because such secrets, if committed, pose an immediate risk of exposure, because they are directly embedded in the codebase.",
        "distractor_analysis": "The distractors suggest impractical manual review, post-deployment network monitoring, or incorrect analysis types (DAST), none of which directly address finding secrets within the static code itself.",
        "analogy": "Using SAST to find secrets in code is like using a metal detector to find hidden coins in sand; it specifically searches the material (code) for a particular type of item (secret)."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "procedure",
      "bloom_level": "apply",
      "prerequisites": [
        "SAST",
        "SECURE_CODING_PRACTICES"
      ]
    },
    {
      "question_text": "What is the primary goal of implementing 'Privacy by Design' principles in software development concerning sensitive data?",
      "correct_answer": "To embed privacy considerations and data protection measures into the system's architecture and design from the outset.",
      "distractors": [
        {
          "text": "To add privacy features only after the software has been fully developed.",
          "misconception": "Targets [timing error]: Privacy by Design emphasizes proactive integration, not reactive patching."
        },
        {
          "text": "To rely solely on legal compliance to ensure data privacy.",
          "misconception": "Targets [compliance vs. proactive design]: Legal compliance is necessary but insufficient; proactive design ensures robust privacy."
        },
        {
          "text": "To make all collected data anonymous by default.",
          "misconception": "Targets [over-simplification]: While anonymization is a tool, Privacy by Design is a broader approach encompassing various protective measures, not just anonymization."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Privacy by Design works by integrating privacy and data protection into the development lifecycle from the very beginning. This proactive approach is essential because retrofitting privacy is costly and less effective than building it in.",
        "distractor_analysis": "The distractors suggest delaying privacy measures, relying only on legal checks, or oversimplifying the approach to anonymization, missing the core principle of proactive, integrated design.",
        "analogy": "Privacy by Design is like building a house with strong foundations and security systems from the start, rather than trying to add them after the house is already built and occupied."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "definition",
      "bloom_level": "understand",
      "prerequisites": [
        "PRIVACY_BY_DESIGN",
        "SECURE_SOFTWARE_DEVELOPMENT_LIFECYCLE"
      ]
    },
    {
      "question_text": "When identifying sensitive data, what is the difference between 'confidential' and 'restricted' data classifications?",
      "correct_answer": "Confidential data typically requires the highest level of protection due to severe impact if disclosed, while restricted data has a significant impact but is less severe than confidential.",
      "distractors": [
        {
          "text": "Confidential data is for internal use only, while restricted data is for public release.",
          "misconception": "Targets [scope confusion]: Both are typically internal; public data is usually 'unclassified' or 'public'."
        },
        {
          "text": "Confidential data is always encrypted, while restricted data is not.",
          "misconception": "Targets [method vs. classification]: Encryption is a control; classification defines the *need* for controls, not the controls themselves."
        },
        {
          "text": "Confidential data relates to financial information, while restricted data relates to personal information.",
          "misconception": "Targets [category confusion]: Both financial and personal data can fall into either 'confidential' or 'restricted' categories depending on severity."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Data classification levels like 'confidential' and 'restricted' denote varying degrees of impact from disclosure. Confidential data implies severe harm, necessitating stringent controls, because its compromise poses the greatest risk.",
        "distractor_analysis": "The distractors confuse internal vs. public access, conflate classification with specific controls (encryption), or incorrectly assign data types to specific classification levels.",
        "analogy": "Think of security clearances: 'Confidential' is like a Top Secret clearance (highest protection), while 'Restricted' might be like a Secret clearance (strong protection, but slightly less stringent than Top Secret)."
      },
      "code_snippets": [],
      "difficulty": "advanced",
      "question_type": "comparison",
      "bloom_level": "analyze",
      "prerequisites": [
        "DATA_CLASSIFICATION_LEVELS",
        "IMPACT_ASSESSMENT"
      ]
    },
    {
      "question_text": "What is the primary security concern when sensitive data is logged by an application?",
      "correct_answer": "The log files themselves may become a target for attackers, potentially exposing sensitive information if not adequately protected.",
      "distractors": [
        {
          "text": "Log files consume excessive disk space, impacting system performance.",
          "misconception": "Targets [performance vs. security]: While log size is a management issue, the primary security concern is data exposure."
        },
        {
          "text": "The logging process itself slows down application execution significantly.",
          "misconception": "Targets [performance vs. security]: Logging overhead is a performance consideration, not the inherent security risk of the logged data."
        },
        {
          "text": "Log files are automatically deleted after a short period, losing valuable audit trails.",
          "misconception": "Targets [retention vs. exposure]: This describes a retention policy issue, not the risk of sensitive data *within* the logs being exposed."
        }
      ],
      "detailed_explanation": {
        "core_logic": "Sensitive data in logs presents a direct security risk because logs are often less protected than primary data stores. If logs are compromised, attackers gain access to potentially sensitive information, because the data is recorded there.",
        "distractor_analysis": "The distractors focus on performance impacts (disk space, execution speed) or log retention policies, rather than the critical security risk of sensitive data exposure within the log files themselves.",
        "analogy": "Leaving sensitive documents unattended on your desk (log files) is risky, even if your desk is in a secure office; someone could still access and read them if the office isn't properly secured."
      },
      "code_snippets": [],
      "difficulty": "intermediate",
      "question_type": "analysis",
      "bloom_level": "analyze",
      "prerequisites": [
        "LOGGING_BEST_PRACTICES",
        "DATA_EXPOSURE_RISKS"
      ]
    }
  ],
  "generation_metadata": {
    "model": "google/gemini-2.5-flash-lite",
    "num_generated": 15,
    "temperature": 0.1,
    "web_citations": [],
    "research_method": "openrouter_web_plugin",
    "search_query": "Sensitive Data Identification Software Development Security best practices",
    "latency_ms": 24822.461
  },
  "timestamp": "2026-01-18T10:55:41.659420"
}