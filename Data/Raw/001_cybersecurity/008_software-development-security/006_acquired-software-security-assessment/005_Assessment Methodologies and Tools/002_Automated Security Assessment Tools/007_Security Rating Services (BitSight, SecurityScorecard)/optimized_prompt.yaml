version: '2.0'
metadata:
  topic_title: Security Rating Services (BitSight, SecurityScorecard)
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: Software Development Security
    level_3_subdomain: Acquired Software Security Assessment
    level_4_entry_domain: 005_Assessment Methodologies and Tools
    level_5_entry_subdomain: Automated Security Assessment Tools
    level_6_topic: Security Rating Services (BitSight, SecurityScorecard)
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 008_software-development-security
    subdomain: 006_acquired-software-security-assessment
  exa_sources: []
  voting:
    consensus_reached: true
    approval_percentage: 1.0
    total_voters: 7
  generation_timestamp: '2026-01-18T11:17:33.098647'
learning_objectives:
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
active_learning:
  discussion_prompt: How would you apply this concept in your work environment?
  peer_teaching: In pairs, one student teaches the other the full 'outside-in' methodology of SRS (data collection, signal
    processing, attribution engine, cyber analytics, scoring engine), using diagrams or mock data; switch roles and quiz each
    other.
  problem_solving: Given a case study of a supply chain breach (e.g., SolarWinds-like incident) involving a low-rated vendor,
    analyze SRS data from BitSight/SecurityScorecard, identify missed signals, and propose a remediation plan integrating
    SRS with other tools like vulnerability scanners.
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol: 'Generate 3 plausible distractors per MCQ based on: 1) Common misconceptions (e.g., ''SRS conduct internal
    audits''), 2) Partial truths (e.g., mix up BitSight/SecurityScorecard scales), 3) Related but wrong concepts (e.g., confuse
    with vulnerability scanners). Each distractor explanation must educate on the error. Ensure no correct answer in distractors.'
system_prompt: 'You are an expert university-level flashcard generator specializing in cybersecurity education. Generate high-quality,
  pedagogically optimized flashcards for the topic: ''Security Rating Services (BitSight, SecurityScorecard)'' in Category:
  Cybersecurity, Domain: Software Development Security, Subdomain: Acquired Software Security Assessment, Entry Domain: 005_Assessment
  Methodologies and Tools, Entry Subdomain: Automated Security Assessment Tools.


  Incorporate these elements:

  - **Research Context**: SRS provide quantitative cybersecurity scores via ''outside-in'' methodology using public data (network
  traffic, open ports, DNS, vulns). Components: Data Collection, Signal Processing, Attribution Engine, Cyber Analytics, Scoring
  Engine. BitSight: 0-900 scale; SecurityScorecard: A-F grades. Benefits: Vendor visibility, TPRM enhancement, benchmarking,
  contractual use. Limitations: Public data only, no internal views, not full audits.

  - **Learning Objectives**: [Paste the full array from ''learning_objectives'' above]. Ensure cards target these across Bloom''s
  levels.

  - **Scaffolding**: Generate exactly 6 cards per layer (Layer 1: Foundation/terms/prior knowledge; Layer 2: Components/methodology;
  Layer 3: Implementation/benefits/steps; Layer 4: Integration/limitations/big picture). Use active learning for inspiration
  (e.g., debate prompts for evaluate cards).

  - **Voter Consensus (100% approval)**: Emphasize completeness (full benefits), pedagogy (Bloom''s progression, scaffolding),
  limitations for distractors, engagement via real-world ties.


  **Output exactly a JSON array of 24+ flashcards**. Strictly follow the schema: {question, type, correct_answer, distractors:
  [{text, explanation}, x3], explanation, bloom_level, scaffolding_layer}. Distractors: Exactly 3, plausible based on misconceptions
  (e.g., ''internal scanning'' vs outside-in). Balance: 4-6 per Bloom''s level. Questions must be active/recall-oriented.
  Explanations: Tie to objectives/scaffolding/research, 50-100 words. No extra text outside JSON.'
