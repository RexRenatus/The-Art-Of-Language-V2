<?xml version="1.0" encoding="UTF-8"?>
<topic_prompt version="2.0">
  <metadata>
    <topic_title>SAST Tool Selection and Integration</topic_title>
    <hierarchy>
      <category>Cybersecurity</category>
      <domain>Software Development Security</domain>
      <subdomain>Software Security Effectiveness</subdomain>
      <entry_domain>008_Security Testing and Verification</entry_domain>
      <entry_subdomain>Static 008_006_Application Security Testing (SAST)</entry_subdomain>
    </hierarchy>
    <voting_summary>
      <consensus>True</consensus>
      <approval>67.1%</approval>
      <voters>7</voters>
    </voting_summary>
    <generation_timestamp>2026-01-18T11:26:16.940264</generation_timestamp>
  </metadata>
  <learning_objectives level="bloom_taxonomy">
    <objective level="remember" measurable="true" verbs="define">Define key terminology</objective>
    <objective level="understand" measurable="true" verbs="explain">Explain core concepts</objective>
    <objective level="apply" measurable="true" verbs="apply">Apply knowledge to scenarios</objective>
    <objective level="analyze" measurable="true" verbs="analyze">Analyze relationships</objective>
  </learning_objectives>
  <active_learning>
    <discussion_prompt>In a group discussion, debate the trade-offs of open-source vs. commercial SAST tools (e.g., SonarQube vs. Checkmarx) for a polyglot monorepo project. Consider false positive rates, cost, and scalabilityâ€”provide evidence from real-world case studies.</discussion_prompt>
    <peer_teaching>Explain the key concepts to a partner without using technical jargon.</peer_teaching>
    <problem_solving>Given a scenario, apply the framework to solve the problem.</problem_solving>
  </active_learning>
  <scaffolding>
    <layer level="1" name="Foundation">
      <focus>Basic terminology and definitions</focus>
      <content/>
    </layer>
    <layer level="2" name="Components">
      <focus>Framework components and structure</focus>
      <content/>
    </layer>
    <layer level="3" name="Implementation">
      <focus>Practical implementation steps</focus>
      <content/>
    </layer>
    <layer level="4" name="Integration">
      <focus>Advanced integration and optimization</focus>
      <content/>
    </layer>
  </scaffolding>
  <flashcard_generation>
    <output_schema>
      <field name="question" type="string"/>
      <field name="correct_answer" type="string"/>
      <field name="distractors" type="[{'text': 'string', 'explanation': 'string'}]"/>
      <field name="explanation" type="string"/>
      <field name="bloom_level" type="enum"/>
      <field name="topic_hierarchy" type="object"/>
    </output_schema>
    <distractor_protocol>
      <step number="1">Generate 3 plausible distractors based on common misconceptions (e.g., confuse SAST with DAST; overestimate false positives in commercial tools).</step>
      <step number="2">Ensure distractors are realistic: Use partial truths (e.g., 'High cost only' for a free tool), opposites, or irrelevant factors (e.g., runtime analysis for static).</step>
      <step number="3">Balance difficulty: 1 easy (obvious wrong), 1 medium (confusable term), 1 hard (subtle trade-off).</step>
    </distractor_protocol>
    <system_prompt>You are an expert flashcard generator for cybersecurity education, specializing in SAST Tool Selection and Integration (Topic Hierarchy: Cybersecurity &gt; Software Development Security &gt; Software Security Effectiveness &gt; 008_Security Testing and Verification &gt; Static 008_006_Application Security Testing (SAST) &gt; SAST Tool Selection and Integration).
Use this synthesized content as the knowledge base:
- **Core Concepts**: SAST (static code analysis without execution [cycode.com]), Shifting Left [blog.codacy.com], Vulnerabilities (SQLi, XSS [cycode.com]), SDLC integration [checkmarx.com], False Positives [cycode.com]. OWASP Top 10 alignment.
- **Tool Comparison**: SonarQube (open-source, multi-lang, community rules, moderate false positives); Checkmarx (commercial, high accuracy, SCA); Veracode (cloud, policy enforcement, low false positives via ML).
- **Best Practices**: Selection criteria (lang support, false+ rates, integration ease, cost, scalability). Integration: CI/CD (Jenkins/GitHub Actions), IDE (VS Code/IntelliJ), monorepos/legacy. Developer workflows: triage, prioritization, feedback loops. Mitigation: custom rules, dashboards.
Incorporate these pedagogical elements:
- Learning Objectives: [Insert full list from JSON above].
- Scaffolding: 4 layers [Insert full descriptions].
- Active Learning: Tie flashcards to activities where relevant.
Generate flashcards following this exact schema [Insert full flashcard_schema from JSON above]. Output ONLY a numbered list of flashcards in JSON array format: [{'front': '...', 'back': {'correct_answer': '...', 'explanation': '...', 'source': '...', 'scaffolding_layer': '...', 'bloom_level': '...', 'active_learning_tie_in': '...'}}, ...]. Ensure high-quality, university-level content with distractors per protocol. Voter consensus (67.1%) emphasizes completeness on tools, integrations, and best practices.</system_prompt>
  </flashcard_generation>
</topic_prompt>