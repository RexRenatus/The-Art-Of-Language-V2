version: '2.0'
metadata:
  topic_title: Privacy Impact Assessment
  hierarchy:
    level_1_category: Cybersecurity
    level_2_domain: Security Architecture And Engineering
    level_3_subdomain: Secure Design Principles
    level_4_entry_domain: Data Protection Design
    level_5_entry_subdomain: Privacy-by-Design
    level_6_topic: Privacy Impact Assessment
  curriculum_type: cybersecurity
  source_folders:
    category: 001_cybersecurity
    domain: 002_security-architecture-and-engineering
    subdomain: 007_secure-design-principles
  exa_sources: []
  voting:
    consensus_reached: true
    approval_percentage: 1.0
    total_voters: 7
  generation_timestamp: '2026-01-01T15:13:00.433406'
learning_objectives:
  remember:
  - objective: Define key terminology
    verbs:
    - define
    measurable: true
  understand:
  - objective: Explain core concepts
    verbs:
    - explain
    measurable: true
  analyze:
  - objective: Analyze relationships
    verbs:
    - analyze
    measurable: true
  apply:
  - objective: Apply knowledge to scenarios
    verbs:
    - apply
    measurable: true
active_learning:
  discussion_prompt: In groups, debate whether a new smart home device collecting voice data requires a full PIA. Identify
    potential privacy risks (e.g., sensitive information like health discussions), compare with non-examples like anonymous
    analytics, and propose mitigations using the NIST Privacy Framework. Address common misconceptions such as PIAs being
    only a regulatory checkbox.
  peer_teaching: Students pair up; one explains PIA steps and Privacy-by-Design using a partner-sharing app example (linking
    to prior knowledge of basic risk assessment and personal data concepts), then switch for teach-back on ERM integration.
    This clarifies confusion between privacy and security.
  problem_solving: Teams conduct a mock PIA for a real-world scenario, e.g., a fitness app sharing data with insurers. Identify
    risks, assess impacts, recommend controls, and role-play a stakeholder review meeting. Analyze case studies like the Equifax
    breach for what a PIA could have prevented. Conclude with think-pair-share on non-examples (e.g., non-personal data projects).
  additional_activities: []
scaffolding:
- level: 1
  name: Foundation
  focus: Basic terminology and definitions
  content: ''
- level: 2
  name: Components
  focus: Framework components and structure
  content: ''
- level: 3
  name: Implementation
  focus: Practical implementation steps
  content: ''
- level: 4
  name: Integration
  focus: Advanced integration and optimization
  content: ''
flashcard_generation:
  output_schema:
    question: string
    correct_answer: string
    distractors:
    - text: string
      explanation: string
    explanation: string
    bloom_level: enum
    topic_hierarchy: object
  distractor_protocol: 'Generate 3 distractors per MCQ: 1. Common misconception (e.g., privacy=security), 2. Partial truth/over-simplification
    (e.g., ignore sensitive info), 3. Non-example confusion (e.g., anonymous data requires PIA). Ensure plausible for university-level
    learners.'
system_prompt: 'You are an expert flashcard generator for cybersecurity education, specializing in Privacy Impact Assessment
  (PIA) under the topic hierarchy: Cybersecurity > Security Architecture And Engineering > Secure Design Principles > Data
  Protection Design > Privacy-by-Design > Privacy Impact Assessment.


  Generate 40 high-quality flashcards (10 per scaffolding layer) optimized for university pedagogy: Bloom''s Taxonomy (use
  provided objectives), active learning (reference activities), scaffolding (Layer 1-4), and spaced repetition best practices.
  Incorporate research context: PIA as systematic process for privacy impacts; core concepts (personal/sensitive info, privacy
  risk, PbD, ERM); standards (NIST Privacy Framework: Govern/Identify/Control/Communicate/Map; full OAIC Guide steps: 1. Describe
  project, 2. Map info flows, 3. Identify privacy issues, 4. Consult stakeholders, 5. Evaluate risks/impacts, 6. Recommend
  mitigations, 7. Plan/report; templates/examples). Sources: NISTIR 8432 (https://nvlpubs.nist.gov/nistpubs/ir/2020/NIST.IR.8432.pdf),
  OAIC Guide (https://www.oaic.gov.au/privacy/privacy-guidance-for-organisations-and-government-agencies/conducting-privacy-impact-assessments),
  ISO 29134, GDPR Art. 35 DPIA.


  Include: Concept map (PIA central: Inputs>Process>Outputs; links PbD/ERM); misconceptions (PIAâ‰ checkbox; privacy core to
  design); prior links (risk mgmt, personal data); voter activities/examples.


  **Output Format (JSON array of flashcards):** Each card: {"front": "Question", "back": {"answer": "...", "explanation":
  "... (link to objective/layer/activity/sources)", "distractors": ["d1", "d2", "d3"] (if MCQ), "bloom_level": "REMEMBER",
  "layer": "1"}}


  Distribute: 30% REMEMBER/UNDERSTAND, 40% APPLY/ANALYZE, 30% EVALUATE/CREATE. 50% MCQ with distractors. Vary types: def,
  compare, apply scenario, critique, create prompt. Ensure active recall, no cues.'
